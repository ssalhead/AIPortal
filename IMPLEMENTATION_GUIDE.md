# AI í¬íƒˆ êµ¬í˜„ ê°€ì´ë“œë¼ì¸
## ê°œë°œìë¥¼ ìœ„í•œ ì‹¤ì „ êµ¬í˜„ ê°€ì´ë“œ

---

## ğŸ¯ êµ¬í˜„ ì² í•™

### Vibe Coding ì‹¤ì²œë²•
- **ëª…ì„¸ì„œëŠ” ë‚˜ì¹¨ë°˜**: ë°©í–¥ì„±ì„ ì œì‹œí•˜ë˜, ìµœì  êµ¬í˜„ì€ ê°œë°œ ì¤‘ ê²°ì •
- **ë‹¨ê³„ì  ì™„ì„±**: ë§¤ ì»¤ë°‹ë§ˆë‹¤ ë™ì‘í•˜ëŠ” ê¸°ëŠ¥ ë‹¨ìœ„ë¡œ êµ¬í˜„
- **í’ˆì§ˆ ìš°ì„ **: ë¹ ë¥¸ êµ¬í˜„ë³´ë‹¤ ê²¬ê³ í•œ êµ¬í˜„ì— ì§‘ì¤‘
- **ì‚¬ìš©ì ì¤‘ì‹¬**: ê¸°ìˆ ì  ì™„ì„±ë„ë³´ë‹¤ ì‚¬ìš©ì ê°€ì¹˜ ìš°ì„ 

### ì½”ë“œ í’ˆì§ˆ ê¸°ì¤€
```python
# ì¢‹ì€ ì˜ˆ: ëª…í™•í•˜ê³  í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ êµ¬í˜„
class WebSearchAgent:
    """ì›¹ ê²€ìƒ‰ì„ ë‹´ë‹¹í•˜ëŠ” ì—ì´ì „íŠ¸
    
    Args:
        llm_router: LLM ë¼ìš°íŒ… ì‹œìŠ¤í…œ
        cache_manager: ìºì‹œ ê´€ë¦¬ì
        
    Example:
        >>> agent = WebSearchAgent(llm_router, cache_manager)
        >>> result = await agent.execute("ìµœì‹  AI íŠ¸ë Œë“œ")
        >>> assert result.sources is not None
    """
    
    def __init__(self, llm_router: LLMRouter, cache_manager: CacheManager):
        self.llm_router = llm_router
        self.cache_manager = cache_manager
        self.search_client = None  # ì§€ì—° ì´ˆê¸°í™”
    
    async def execute(self, query: str, context: Dict = None) -> SearchResult:
        """ê²€ìƒ‰ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""
        
        # ì…ë ¥ ê²€ì¦
        if not query or len(query.strip()) == 0:
            raise ValueError("ê²€ìƒ‰ì–´ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ìºì‹œ í™•ì¸
        cache_key = f"search:{hashlib.sha256(query.encode()).hexdigest()[:16]}"
        cached_result = await self.cache_manager.get(cache_key)
        if cached_result:
            return SearchResult.from_dict(cached_result)
        
        try:
            # ì‹¤ì œ ê²€ìƒ‰ ì‹¤í–‰
            result = await self._perform_search(query, context)
            
            # ê²°ê³¼ ìºì‹±
            await self.cache_manager.set(
                cache_key, 
                result.to_dict(), 
                ttl=1800,  # 30ë¶„
                tags=['search', f'user:{context.get("user_id")}']
            )
            
            return result
            
        except Exception as e:
            # êµ¬ì¡°í™”ëœ ì—ëŸ¬ ì²˜ë¦¬
            logger.error(f"ê²€ìƒ‰ ì‹¤í–‰ ì‹¤íŒ¨: {query}", exc_info=True)
            raise AgentExecutionError(f"ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

# ë‚˜ìœ ì˜ˆ: ë¶ˆë¶„ëª…í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ê¸° ì–´ë ¤ìš´ êµ¬í˜„
def search(q, u=None):
    if not q: return None
    # ë¬´ì—‡ì„ í•˜ëŠ”ì§€ ì•Œê¸° ì–´ë ¤ì›€
    r = requests.get(f"https://api.search.com?q={q}&u={u}")
    return r.json() if r.status_code == 200 else None
```

---

## ğŸ”§ ê°œë°œ í™˜ê²½ ì„¤ì •

### 1. ê°œë°œ í™˜ê²½ ì´ˆê¸° ì„¤ì •
```bash
# í”„ë¡œì íŠ¸ í´ë¡  ë° ê¸°ë³¸ ì„¤ì •
git clone <repository-url>
cd AIPortal

# ë°±ì—”ë“œ í™˜ê²½ ì„¤ì •
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# í”„ë¡ íŠ¸ì—”ë“œ í™˜ê²½ ì„¤ì •
cd ../frontend
npm install

# ê°œë°œ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
cd ..
docker-compose -f docker-compose.dev.yml up -d postgres

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ í¸ì§‘í•˜ì—¬ ì‹¤ì œ ê°’ ì„¤ì •
```

### 2. ë¡œì»¬ ê°œë°œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
```bash
# í†µí•© ê°œë°œ ì„œë²„ ì‹¤í–‰
./scripts/start-dev.sh

# ë˜ëŠ” ê°œë³„ ì‹¤í–‰
cd backend && uvicorn app.main:app --reload --port 8000
cd frontend && npm run dev
```

### 3. ê°œë°œ ë„êµ¬ ì„¤ì •
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./backend/venv/bin/python",
    "python.formatting.provider": "black",
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true,
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    },
    "typescript.preferences.importModuleSpecifier": "relative",
    "eslint.validate": ["javascript", "typescript", "typescriptreact"]
}

// .vscode/extensions.json
{
    "recommendations": [
        "ms-python.python",
        "ms-python.black-formatter", 
        "bradlc.vscode-tailwindcss",
        "esbenp.prettier-vscode",
        "ms-vscode.vscode-typescript-next"
    ]
}
```

---

## ğŸ—ï¸ ë°±ì—”ë“œ êµ¬í˜„ ê°€ì´ë“œ

### FastAPI í”„ë¡œì íŠ¸ êµ¬ì¡°
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # ì•± ì§„ì…ì 
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # ì„¤ì • ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ security.py        # ë³´ì•ˆ ê´€ë ¨
â”‚   â”‚   â””â”€â”€ exceptions.py      # ì»¤ìŠ¤í…€ ì˜ˆì™¸
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ deps.py            # ì˜ì¡´ì„± ì£¼ì…
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ chat.py        # ì±„íŒ… API
â”‚   â”‚       â”œâ”€â”€ agents.py      # ì—ì´ì „íŠ¸ API
â”‚   â”‚       â”œâ”€â”€ workspaces.py  # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ API
â”‚   â”‚       â””â”€â”€ files.py       # íŒŒì¼ ê´€ë¦¬ API
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base.py           # ê¸°ë³¸ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ supervisor.py     # ì¤‘ì•™ ì¡°ì • ì—ì´ì „íŠ¸
â”‚   â”‚   â”œâ”€â”€ llm_router.py     # LLM ë¼ìš°íŒ…
â”‚   â”‚   â””â”€â”€ workers/          # Worker ì—ì´ì „íŠ¸ë“¤
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ base.py           # DB ê¸°ë³¸ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ session.py        # DB ì„¸ì…˜ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ models/           # SQLAlchemy ëª¨ë¸
â”‚   â”œâ”€â”€ schemas/              # Pydantic ìŠ¤í‚¤ë§ˆ
â”‚   â”œâ”€â”€ services/            # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â””â”€â”€ utils/               # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ tests/                   # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”œâ”€â”€ alembic/                # DB ë§ˆì´ê·¸ë ˆì´ì…˜
â””â”€â”€ requirements.txt
```

### í•µì‹¬ í´ë˜ìŠ¤ êµ¬í˜„ ì˜ˆì œ

#### 1. ê¸°ë³¸ ì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤
```python
# app/agents/base.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from pydantic import BaseModel
import asyncio
import time
from dataclasses import dataclass

@dataclass
class AgentResult:
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼"""
    content: str
    metadata: Dict[str, Any]
    success: bool
    execution_time: float
    tokens_used: Optional[int] = None
    model_used: Optional[str] = None
    sources: Optional[list] = None

class BaseAgent(ABC):
    """ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
        self.execution_count = 0
        self.total_execution_time = 0.0
    
    @abstractmethod
    async def execute(self, input_data: Dict[str, Any], context: Dict[str, Any] = None) -> AgentResult:
        """ì—ì´ì „íŠ¸ í•µì‹¬ ë¡œì§ ì‹¤í–‰"""
        pass
    
    async def _execute_with_metrics(self, input_data: Dict[str, Any], context: Dict[str, Any] = None) -> AgentResult:
        """ë©”íŠ¸ë¦­ê³¼ í•¨ê»˜ ì‹¤í–‰"""
        start_time = time.time()
        self.execution_count += 1
        
        try:
            result = await self.execute(input_data, context)
            result.execution_time = time.time() - start_time
            self.total_execution_time += result.execution_time
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            AGENT_EXECUTIONS.labels(
                agent_type=self.name,
                status='success'
            ).inc()
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            self.total_execution_time += execution_time
            
            AGENT_EXECUTIONS.labels(
                agent_type=self.name,
                status='error'
            ).inc()
            
            raise AgentExecutionError(f"{self.name} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
    
    def get_stats(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ í†µê³„ ì •ë³´"""
        avg_time = self.total_execution_time / max(self.execution_count, 1)
        return {
            'name': self.name,
            'execution_count': self.execution_count,
            'total_execution_time': self.total_execution_time,
            'average_execution_time': avg_time
        }

class AgentExecutionError(Exception):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ë°œìƒí•˜ëŠ” ì—ëŸ¬"""
    pass
```

#### 2. ì‹¤ì œ Worker ì—ì´ì „íŠ¸ êµ¬í˜„
```python
# app/agents/workers/web_search.py
from app.agents.base import BaseAgent, AgentResult
from app.core.config import settings
import aiohttp
import asyncio
from typing import Dict, Any, List

class WebSearchAgent(BaseAgent):
    """ì›¹ ê²€ìƒ‰ ì „ë¬¸ ì—ì´ì „íŠ¸"""
    
    def __init__(self, llm_router, cache_manager):
        super().__init__("WebSearchAgent", "ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ë° ì •ë³´ ìˆ˜ì§‘")
        self.llm_router = llm_router
        self.cache_manager = cache_manager
        self.session = None
    
    async def _get_session(self) -> aiohttp.ClientSession:
        """HTTP ì„¸ì…˜ ì§€ì—° ì´ˆê¸°í™”"""
        if self.session is None or self.session.closed:
            timeout = aiohttp.ClientTimeout(total=30, connect=10)
            connector = aiohttp.TCPConnector(limit=100, ttl_dns_cache=300)
            self.session = aiohttp.ClientSession(
                timeout=timeout,
                connector=connector,
                headers={'User-Agent': 'AI-Portal/1.0'}
            )
        return self.session
    
    async def execute(self, input_data: Dict[str, Any], context: Dict[str, Any] = None) -> AgentResult:
        """ì›¹ ê²€ìƒ‰ ì‹¤í–‰"""
        query = input_data.get('query')
        if not query:
            raise ValueError("ê²€ìƒ‰ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ìºì‹œ í™•ì¸
        cache_key = f"websearch:{hashlib.sha256(query.encode()).hexdigest()[:16]}"
        cached = await self.cache_manager.get(cache_key)
        if cached:
            return AgentResult(**cached)
        
        try:
            # 1. ì›¹ ê²€ìƒ‰ ì‹¤í–‰
            search_results = await self._perform_web_search(query)
            
            # 2. ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½
            summary = await self._summarize_results(query, search_results, context)
            
            # 3. ê²°ê³¼ êµ¬ì¡°í™”
            result = AgentResult(
                content=summary,
                metadata={
                    'query': query,
                    'search_engine': 'multiple',
                    'results_count': len(search_results)
                },
                success=True,
                execution_time=0,  # ë©”íŠ¸ë¦­ì—ì„œ ê³„ì‚°ë¨
                sources=search_results
            )
            
            # ìºì‹œ ì €ì¥
            await self.cache_manager.set(
                cache_key,
                result.__dict__,
                ttl=1800,  # 30ë¶„
                tags=['websearch', f'user:{context.get("user_id", "anonymous")}']
            )
            
            return result
            
        except Exception as e:
            return AgentResult(
                content=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                metadata={'error': str(e)},
                success=False,
                execution_time=0
            )
    
    async def _perform_web_search(self, query: str) -> List[Dict[str, Any]]:
        """ì‹¤ì œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (ì—¬ëŸ¬ ê²€ìƒ‰ ì—”ì§„ í†µí•©)"""
        session = await self._get_session()
        
        # ì—¬ëŸ¬ ê²€ìƒ‰ ì†ŒìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
        tasks = [
            self._search_serper(session, query),
            self._search_tavily(session, query),
            # ì¶”ê°€ ê²€ìƒ‰ ì†ŒìŠ¤ë“¤...
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
        all_results = []
        for result in results:
            if isinstance(result, list):
                all_results.extend(result)
        
        return self._deduplicate_results(all_results)
    
    async def _search_serper(self, session: aiohttp.ClientSession, query: str) -> List[Dict]:
        """Serper APIë¥¼ í†µí•œ Google ê²€ìƒ‰"""
        url = "https://google.serper.dev/search"
        headers = {"X-API-KEY": settings.SERPER_API_KEY}
        payload = {"q": query, "num": 10}
        
        try:
            async with session.post(url, json=payload, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()
                    return [
                        {
                            'title': item['title'],
                            'url': item['link'],
                            'snippet': item['snippet'],
                            'source': 'google'
                        }
                        for item in data.get('organic', [])
                    ]
        except Exception as e:
            print(f"Serper ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return []
    
    async def _summarize_results(self, query: str, results: List[Dict], context: Dict) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMìœ¼ë¡œ ìš”ì•½"""
        if not results:
            return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        results_text = "\n\n".join([
            f"ì œëª©: {r['title']}\nì¶œì²˜: {r['url']}\në‚´ìš©: {r['snippet']}"
            for r in results[:10]  # ìƒìœ„ 10ê°œë§Œ ì‚¬ìš©
        ])
        
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ '{query}'ì— ëŒ€í•œ í¬ê´„ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ê²€ìƒ‰ ê²°ê³¼:
{results_text}

ìš”êµ¬ì‚¬í•­:
1. ì •í™•í•˜ê³  ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
2. ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œ
3. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±
4. ì¤‘ìš”í•œ ì •ë³´ëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì‚¬ì‹¤ í¬í•¨

ë‹µë³€:
        """
        
        # ìµœì  ëª¨ë¸ ì„ íƒ ë° ìš”ì•½ ìƒì„±
        model = await self.llm_router.get_optimal_model(
            task_type="balanced_reasoning",
            context_length=len(prompt)
        )
        
        try:
            response = await model.ainvoke(prompt)
            return response.content
        except Exception as e:
            # í´ë°±: ê°„ë‹¨í•œ ê²°ê³¼ ì •ë¦¬
            return self._create_simple_summary(query, results)
    
    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ê²°ê³¼ ì œê±°"""
        seen_urls = set()
        unique_results = []
        
        for result in results:
            url = result.get('url', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
        
        return unique_results[:15]  # ìµœëŒ€ 15ê°œ ê²°ê³¼
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.session and not self.session.closed:
            await self.session.close()
```

#### 3. API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
```python
# app/api/v1/chat.py
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse
from app.schemas.chat import ChatRequest, ChatResponse
from app.services.agent_service import AgentService
from app.core.security import get_current_user
from app.db.session import get_db
import json
import asyncio

router = APIRouter()

@router.post("/chat", response_model=ChatResponse)
async def chat(
    request: ChatRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
    agent_service: AgentService = Depends()
):
    """ì±„íŒ… API - ì—ì´ì „íŠ¸ì™€ì˜ ëŒ€í™”"""
    
    try:
        # ìš”ì²­ ê²€ì¦
        if not request.message.strip():
            raise HTTPException(status_code=400, detail="ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = {
            'user_id': current_user['empno'],
            'user_profile': current_user.get('profile_data', {}),
            'workspace_id': request.workspace_id,
            'preferences': current_user.get('preferences', {})
        }
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = await agent_service.execute_agent(
            message=request.message,
            agent_type=request.agent_type,
            context=context,
            model_preference=request.model_preference
        )
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…: ëŒ€í™” ê¸°ë¡ ì €ì¥, í”„ë¡œíŒŒì¼ ì—…ë°ì´íŠ¸
        background_tasks.add_task(
            _save_conversation,
            db, current_user['empno'], request, result
        )
        
        return ChatResponse(
            message=result.content,
            agent_type=request.agent_type,
            model_used=result.model_used,
            sources=result.sources,
            metadata=result.metadata,
            success=result.success
        )
        
    except Exception as e:
        # êµ¬ì¡°í™”ëœ ì—ëŸ¬ ì‘ë‹µ
        logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500, 
            detail=f"ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.post("/chat/stream")
async def chat_stream(
    request: ChatRequest,
    current_user: dict = Depends(get_current_user),
    agent_service: AgentService = Depends()
):
    """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… API"""
    
    async def generate_response():
        try:
            context = {
                'user_id': current_user['empno'],
                'user_profile': current_user.get('profile_data', {}),
                'streaming': True
            }
            
            # ìŠ¤íŠ¸ë¦¬ë° ì—ì´ì „íŠ¸ ì‹¤í–‰
            async for chunk in agent_service.execute_agent_stream(
                message=request.message,
                agent_type=request.agent_type,
                context=context
            ):
                yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
                
        except Exception as e:
            error_chunk = {
                'type': 'error',
                'content': f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'finished': True
            }
            yield f"data: {json.dumps(error_chunk, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_response(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )

async def _save_conversation(db: AsyncSession, user_id: str, request: ChatRequest, result):
    """ëŒ€í™” ê¸°ë¡ ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
    try:
        # ëŒ€í™” ì €ì¥ ë¡œì§
        conversation = await db.execute(
            """
            INSERT INTO conversations (user_empno, workspace_id, context)
            VALUES ($1, $2, $3) ON CONFLICT DO NOTHING
            RETURNING id
            """,
            user_id, request.workspace_id, {}
        )
        
        # ë©”ì‹œì§€ ì €ì¥
        await db.execute(
            """
            INSERT INTO messages (conversation_id, role, content, metadata, agent_type, model_used)
            VALUES ($1, 'user', $2, '{}', NULL, NULL),
                   ($1, 'assistant', $3, $4, $5, $6)
            """,
            conversation['id'],
            request.message,
            result.content,
            json.dumps(result.metadata),
            request.agent_type,
            result.model_used
        )
        
        await db.commit()
        
    except Exception as e:
        logger.error(f"ëŒ€í™” ì €ì¥ ì‹¤íŒ¨: {e}")
        await db.rollback()
```

---

## âš›ï¸ í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ ê°€ì´ë“œ

### React í”„ë¡œì íŠ¸ êµ¬ì¡°
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessage.tsx      # ë©”ì‹œì§€ ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx        # ì…ë ¥ ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ ModelSelector.tsx    # ëª¨ë¸ ì„ íƒ
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ workspace/
â”‚   â”‚   â”‚   â”œâ”€â”€ WorkspaceEditor.tsx  # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ í¸ì§‘ê¸°
â”‚   â”‚   â”‚   â”œâ”€â”€ ArtifactRenderer.tsx # ì•„í‹°íŒ©íŠ¸ ë Œë”ëŸ¬
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â”‚   â”œâ”€â”€ Loading.tsx          # ë¡œë”© ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorBoundary.tsx    # ì—ëŸ¬ ê²½ê³„
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â””â”€â”€ ui/                      # ì¬ì‚¬ìš© ê°€ëŠ¥í•œ UI ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ ChatPage.tsx            # ì±„íŒ… í˜ì´ì§€
â”‚   â”‚   â”œâ”€â”€ WorkspacePage.tsx       # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ í˜ì´ì§€
â”‚   â”‚   â””â”€â”€ SettingsPage.tsx        # ì„¤ì • í˜ì´ì§€
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useChat.ts              # ì±„íŒ… ê´€ë ¨ í›…
â”‚   â”‚   â”œâ”€â”€ useWebSocket.ts         # WebSocket í›…
â”‚   â”‚   â””â”€â”€ useAgent.ts             # ì—ì´ì „íŠ¸ ê´€ë ¨ í›…
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ api.ts                  # API í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ websocket.ts            # WebSocket ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ storage.ts              # ë¡œì»¬ ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”œâ”€â”€ chatStore.ts            # ì±„íŒ… ìƒíƒœ
â”‚   â”‚   â”œâ”€â”€ workspaceStore.ts       # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ìƒíƒœ
â”‚   â”‚   â””â”€â”€ userStore.ts            # ì‚¬ìš©ì ìƒíƒœ
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ index.ts                # íƒ€ì… ì •ì˜
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ index.ts                # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â””â”€â”€ App.tsx
â”œâ”€â”€ public/
â””â”€â”€ package.json
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸ êµ¬í˜„

#### 1. ì±„íŒ… ë©”ì‹œì§€ ì»´í¬ë„ŒíŠ¸
```typescript
// src/components/chat/ChatMessage.tsx
import React, { memo } from 'react';
import { Message, MessageSource } from '@/types';
import { cn } from '@/utils';
import { Avatar, AvatarFallback } from '@/components/ui/avatar';
import { Badge } from '@/components/ui/badge';
import { Card, CardContent } from '@/components/ui/card';
import { ExternalLink, Copy, ChevronDown } from 'lucide-react';
import { useState } from 'react';

interface ChatMessageProps {
  message: Message;
  isStreaming?: boolean;
  onSourceClick?: (source: MessageSource) => void;
}

export const ChatMessage = memo<ChatMessageProps>(({ 
  message, 
  isStreaming = false,
  onSourceClick 
}) => {
  const [showSources, setShowSources] = useState(false);
  const [copied, setCopied] = useState(false);

  const isUser = message.role === 'user';
  const hasError = !message.success && message.role === 'assistant';

  const handleCopy = async () => {
    try {
      await navigator.clipboard.writeText(message.content);
      setCopied(true);
      setTimeout(() => setCopied(false), 2000);
    } catch (error) {
      console.error('ë³µì‚¬ ì‹¤íŒ¨:', error);
    }
  };

  const renderContent = () => {
    if (hasError) {
      return (
        <div className="text-red-600 bg-red-50 p-3 rounded-lg border border-red-200">
          <p className="font-medium">ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤</p>
          <p className="text-sm mt-1">{message.content}</p>
        </div>
      );
    }

    return (
      <div className="prose prose-sm max-w-none">
        <ReactMarkdown
          components={{
            code: ({ node, inline, className, children, ...props }) => {
              const match = /language-(\w+)/.exec(className || '');
              return !inline && match ? (
                <SyntaxHighlighter
                  style={oneLight}
                  language={match[1]}
                  PreTag="div"
                  {...props}
                >
                  {String(children).replace(/\n$/, '')}
                </SyntaxHighlighter>
              ) : (
                <code className={cn("px-1 py-0.5 bg-gray-100 rounded text-sm", className)} {...props}>
                  {children}
                </code>
              );
            },
            a: ({ href, children }) => (
              <a 
                href={href} 
                target="_blank" 
                rel="noopener noreferrer"
                className="text-blue-600 hover:underline inline-flex items-center gap-1"
              >
                {children}
                <ExternalLink className="w-3 h-3" />
              </a>
            )
          }}
        >
          {message.content}
        </ReactMarkdown>
        {isStreaming && <span className="animate-pulse">â–‹</span>}
      </div>
    );
  };

  const renderSources = () => {
    if (!message.sources || message.sources.length === 0) return null;

    return (
      <div className="mt-3">
        <button
          onClick={() => setShowSources(!showSources)}
          className="flex items-center gap-2 text-sm text-gray-600 hover:text-gray-800 transition-colors"
        >
          <ChevronDown 
            className={cn("w-4 h-4 transition-transform", showSources && "rotate-180")}
          />
          ì¶œì²˜ {message.sources.length}ê°œ
        </button>

        {showSources && (
          <div className="mt-2 space-y-2">
            {message.sources.map((source, index) => (
              <Card 
                key={index}
                className="p-3 hover:bg-gray-50 cursor-pointer transition-colors"
                onClick={() => onSourceClick?.(source)}
              >
                <CardContent className="p-0">
                  <div className="flex items-start justify-between">
                    <div className="flex-1 min-w-0">
                      <h4 className="font-medium text-sm truncate">{source.title}</h4>
                      <p className="text-xs text-gray-600 mt-1 line-clamp-2">
                        {source.snippet}
                      </p>
                      <div className="flex items-center gap-2 mt-2">
                        <Badge variant="secondary" className="text-xs">
                          {source.source}
                        </Badge>
                        <a 
                          href={source.url}
                          target="_blank"
                          rel="noopener noreferrer"
                          className="text-xs text-blue-600 hover:underline"
                          onClick={(e) => e.stopPropagation()}
                        >
                          ì›ë³¸ ë³´ê¸°
                        </a>
                      </div>
                    </div>
                  </div>
                </CardContent>
              </Card>
            ))}
          </div>
        )}
      </div>
    );
  };

  return (
    <div className={cn(
      "flex gap-3 p-4",
      isUser ? "flex-row-reverse" : "flex-row"
    )}>
      {/* ì•„ë°”íƒ€ */}
      <Avatar className={cn("w-8 h-8", isUser && "bg-blue-500")}>
        <AvatarFallback>
          {isUser ? "You" : "AI"}
        </AvatarFallback>
      </Avatar>

      {/* ë©”ì‹œì§€ ë‚´ìš© */}
      <div className={cn(
        "flex-1 max-w-3xl",
        isUser ? "text-right" : "text-left"
      )}>
        {/* ë©”íƒ€ ì •ë³´ */}
        <div className={cn(
          "flex items-center gap-2 mb-2",
          isUser ? "justify-end" : "justify-start"
        )}>
          <span className="text-sm font-medium">
            {isUser ? "You" : "AI Assistant"}
          </span>
          
          {message.agent_type && !isUser && (
            <Badge variant="outline" className="text-xs">
              {message.agent_type}
            </Badge>
          )}
          
          {message.model_used && !isUser && (
            <Badge variant="secondary" className="text-xs">
              {message.model_used}
            </Badge>
          )}

          <button
            onClick={handleCopy}
            className="p-1 hover:bg-gray-100 rounded transition-colors"
            title="ë³µì‚¬"
          >
            <Copy className="w-3 h-3" />
          </button>
        </div>

        {/* ë©”ì‹œì§€ ë³¸ë¬¸ */}
        <div className={cn(
          "rounded-lg px-4 py-3",
          isUser 
            ? "bg-blue-500 text-white ml-auto max-w-md" 
            : "bg-gray-100 text-gray-900"
        )}>
          {renderContent()}
        </div>

        {/* ì¶œì²˜ ì •ë³´ */}
        {!isUser && renderSources()}

        {/* ë³µì‚¬ ì™„ë£Œ ì•Œë¦¼ */}
        {copied && (
          <div className="text-xs text-green-600 mt-1">
            ë³µì‚¬ ì™„ë£Œ!
          </div>
        )}
      </div>
    </div>
  );
});

ChatMessage.displayName = 'ChatMessage';
```

#### 2. ì±„íŒ… ì…ë ¥ ì»´í¬ë„ŒíŠ¸
```typescript
// src/components/chat/ChatInput.tsx
import React, { useState, useRef, useCallback } from 'react';
import { Send, Paperclip, Square } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { useChat } from '@/hooks/useChat';
import { cn } from '@/utils';

interface ChatInputProps {
  onSendMessage: (message: string, files?: File[]) => void;
  isLoading?: boolean;
  disabled?: boolean;
  placeholder?: string;
  maxLength?: number;
}

export const ChatInput: React.FC<ChatInputProps> = ({
  onSendMessage,
  isLoading = false,
  disabled = false,
  placeholder = "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
  maxLength = 10000
}) => {
  const [message, setMessage] = useState('');
  const [files, setFiles] = useState<File[]>([]);
  const [isDragging, setIsDragging] = useState(false);
  
  const textareaRef = useRef<HTMLTextAreaElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  
  const { stopGeneration } = useChat();

  // ìë™ ë†’ì´ ì¡°ì ˆ
  const adjustTextareaHeight = useCallback(() => {
    if (textareaRef.current) {
      textareaRef.current.style.height = 'auto';
      textareaRef.current.style.height = `${textareaRef.current.scrollHeight}px`;
    }
  }, []);

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    
    if (!message.trim() && files.length === 0) return;
    if (isLoading || disabled) return;

    onSendMessage(message.trim(), files);
    setMessage('');
    setFiles([]);
    
    // í…ìŠ¤íŠ¸ì˜ì—­ ë†’ì´ ë¦¬ì…‹
    if (textareaRef.current) {
      textareaRef.current.style.height = 'auto';
    }
  };

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit(e);
    }
  };

  const handleFileSelect = (e: React.ChangeEvent<HTMLInputElement>) => {
    const selectedFiles = Array.from(e.target.files || []);
    setFiles(prev => [...prev, ...selectedFiles]);
  };

  const handleDrop = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(false);
    
    const droppedFiles = Array.from(e.dataTransfer.files);
    setFiles(prev => [...prev, ...droppedFiles]);
  };

  const removeFile = (index: number) => {
    setFiles(prev => prev.filter((_, i) => i !== index));
  };

  const remainingChars = maxLength - message.length;
  const isNearLimit = remainingChars < 100;

  return (
    <div className="border-t bg-white">
      {/* íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° */}
      {files.length > 0 && (
        <div className="px-4 py-2 border-b bg-gray-50">
          <div className="flex flex-wrap gap-2">
            {files.map((file, index) => (
              <div 
                key={index}
                className="flex items-center gap-2 bg-white rounded px-3 py-1 text-sm border"
              >
                <Paperclip className="w-4 h-4" />
                <span className="max-w-32 truncate">{file.name}</span>
                <button
                  onClick={() => removeFile(index)}
                  className="text-red-500 hover:text-red-700"
                >
                  Ã—
                </button>
              </div>
            ))}
          </div>
        </div>
      )}

      {/* ì…ë ¥ ì˜ì—­ */}
      <form onSubmit={handleSubmit} className="p-4">
        <div 
          className={cn(
            "relative border rounded-lg focus-within:ring-2 focus-within:ring-blue-500 transition-colors",
            isDragging && "border-blue-500 bg-blue-50",
            disabled && "opacity-50"
          )}
          onDragOver={(e) => {
            e.preventDefault();
            setIsDragging(true);
          }}
          onDragLeave={() => setIsDragging(false)}
          onDrop={handleDrop}
        >
          <Textarea
            ref={textareaRef}
            value={message}
            onChange={(e) => {
              setMessage(e.target.value);
              adjustTextareaHeight();
            }}
            onKeyDown={handleKeyDown}
            placeholder={placeholder}
            disabled={disabled}
            maxLength={maxLength}
            className="resize-none border-0 focus:ring-0 pr-24 min-h-[3rem] max-h-40"
            rows={1}
          />

          {/* ìš°ì¸¡ ë²„íŠ¼ë“¤ */}
          <div className="absolute right-2 bottom-2 flex items-center gap-2">
            {/* íŒŒì¼ ì—…ë¡œë“œ ë²„íŠ¼ */}
            <Button
              type="button"
              variant="ghost"
              size="sm"
              onClick={() => fileInputRef.current?.click()}
              disabled={disabled}
              className="p-2"
            >
              <Paperclip className="w-4 h-4" />
            </Button>

            {/* ì „ì†¡/ì¤‘ë‹¨ ë²„íŠ¼ */}
            {isLoading ? (
              <Button
                type="button"
                onClick={stopGeneration}
                variant="destructive"
                size="sm"
                className="p-2"
              >
                <Square className="w-4 h-4" />
              </Button>
            ) : (
              <Button
                type="submit"
                disabled={(!message.trim() && files.length === 0) || disabled}
                size="sm"
                className="p-2"
              >
                <Send className="w-4 h-4" />
              </Button>
            )}
          </div>
        </div>

        {/* ê¸€ì ìˆ˜ í‘œì‹œ */}
        {isNearLimit && (
          <div className={cn(
            "text-xs mt-1 text-right",
            remainingChars < 0 ? "text-red-500" : "text-gray-500"
          )}>
            {remainingChars} ê¸€ì ë‚¨ìŒ
          </div>
        )}

        {/* ìˆ¨ê²¨ì§„ íŒŒì¼ ì…ë ¥ */}
        <input
          ref={fileInputRef}
          type="file"
          multiple
          accept="image/*,.pdf,.txt,.doc,.docx,.xls,.xlsx"
          onChange={handleFileSelect}
          className="hidden"
        />
      </form>
    </div>
  );
};
```

#### 3. ì±„íŒ… ê´€ë ¨ ì»¤ìŠ¤í…€ í›…
```typescript
// src/hooks/useChat.ts
import { useState, useCallback, useRef } from 'react';
import { useMutation, useQueryClient } from '@tanstack/react-query';
import { apiClient } from '@/services/api';
import { useChatStore } from '@/stores/chatStore';
import { useWebSocket } from '@/hooks/useWebSocket';
import { Message, ChatRequest } from '@/types';
import { toast } from 'sonner';

export const useChat = () => {
  const [isGenerating, setIsGenerating] = useState(false);
  const abortControllerRef = useRef<AbortController | null>(null);
  const queryClient = useQueryClient();
  
  const { 
    messages, 
    addMessage, 
    updateLastMessage, 
    clearMessages,
    currentWorkspaceId 
  } = useChatStore();

  // ë©”ì‹œì§€ ì „ì†¡ ë®¤í…Œì´ì…˜
  const sendMessageMutation = useMutation({
    mutationFn: async ({ message, agentType, files }: {
      message: string;
      agentType?: string;
      files?: File[];
    }) => {
      // íŒŒì¼ì´ ìˆëŠ” ê²½ìš° ì—…ë¡œë“œ ë¨¼ì €
      let uploadedFiles = [];
      if (files && files.length > 0) {
        uploadedFiles = await uploadFiles(files);
      }

      const request: ChatRequest = {
        message,
        agent_type: agentType || 'general',
        workspace_id: currentWorkspaceId,
        files: uploadedFiles.map(f => f.id)
      };

      return apiClient.post('/chat', request);
    },
    onSuccess: (response, variables) => {
      // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
      addMessage({
        id: generateId(),
        role: 'user',
        content: variables.message,
        timestamp: new Date(),
        success: true
      });

      // AI ì‘ë‹µ ì¶”ê°€
      addMessage({
        id: generateId(),
        role: 'assistant',
        content: response.data.message,
        timestamp: new Date(),
        success: response.data.success,
        agent_type: response.data.agent_type,
        model_used: response.data.model_used,
        sources: response.data.sources,
        metadata: response.data.metadata
      });

      // ê´€ë ¨ ì¿¼ë¦¬ ë¬´íš¨í™”
      queryClient.invalidateQueries({ queryKey: ['conversations'] });
    },
    onError: (error) => {
      toast.error('ë©”ì‹œì§€ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      console.error('Chat error:', error);
      
      // ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
      addMessage({
        id: generateId(),
        role: 'assistant',
        content: 'ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        timestamp: new Date(),
        success: false
      });
    }
  });

  // ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ ì „ì†¡
  const sendStreamingMessage = useCallback(async (
    message: string, 
    agentType?: string,
    files?: File[]
  ) => {
    if (isGenerating) return;
    
    try {
      setIsGenerating(true);
      abortControllerRef.current = new AbortController();

      // ì‚¬ìš©ì ë©”ì‹œì§€ ë¨¼ì € ì¶”ê°€
      const userMessage: Message = {
        id: generateId(),
        role: 'user',
        content: message,
        timestamp: new Date(),
        success: true
      };
      addMessage(userMessage);

      // íŒŒì¼ ì—…ë¡œë“œ (ìˆëŠ” ê²½ìš°)
      let uploadedFiles = [];
      if (files && files.length > 0) {
        uploadedFiles = await uploadFiles(files);
      }

      // AI ì‘ë‹µ ë©”ì‹œì§€ ì´ˆê¸°í™”
      const aiMessageId = generateId();
      const aiMessage: Message = {
        id: aiMessageId,
        role: 'assistant',
        content: '',
        timestamp: new Date(),
        success: true
      };
      addMessage(aiMessage);

      // ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
      const response = await fetch('/api/v1/chat/stream', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${localStorage.getItem('access_token')}`
        },
        body: JSON.stringify({
          message,
          agent_type: agentType || 'general',
          workspace_id: currentWorkspaceId,
          files: uploadedFiles.map(f => f.id)
        }),
        signal: abortControllerRef.current.signal
      });

      if (!response.ok) {
        throw new Error('ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì‹¤íŒ¨');
      }

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();

      if (reader) {
        let buffer = '';
        let accumulatedContent = '';

        while (true) {
          const { done, value } = await reader.read();
          
          if (done) break;

          buffer += decoder.decode(value, { stream: true });
          
          // ì™„ë£Œëœ ë¼ì¸ë“¤ ì²˜ë¦¬
          const lines = buffer.split('\n');
          buffer = lines.pop() || ''; // ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë¼ì¸ì€ ë²„í¼ì— ë‚¨ê¹€

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              try {
                const data = JSON.parse(line.slice(6));
                
                if (data.type === 'content') {
                  accumulatedContent += data.content;
                  updateLastMessage(aiMessageId, {
                    content: accumulatedContent,
                    metadata: data.metadata
                  });
                } else if (data.type === 'complete') {
                  updateLastMessage(aiMessageId, {
                    content: accumulatedContent,
                    sources: data.sources,
                    agent_type: data.agent_type,
                    model_used: data.model_used,
                    success: true
                  });
                } else if (data.type === 'error') {
                  updateLastMessage(aiMessageId, {
                    content: data.content,
                    success: false
                  });
                }
              } catch (e) {
                console.warn('ìŠ¤íŠ¸ë¦¼ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨:', line);
              }
            }
          }
        }
      }

    } catch (error: any) {
      if (error.name === 'AbortError') {
        updateLastMessage(aiMessage.id, {
          content: accumulatedContent + '\n\n*ì‘ë‹µì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.*',
          success: false
        });
      } else {
        toast.error('ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        updateLastMessage(aiMessage.id, {
          content: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
          success: false
        });
      }
    } finally {
      setIsGenerating(false);
      abortControllerRef.current = null;
    }
  }, [isGenerating, addMessage, updateLastMessage, currentWorkspaceId]);

  // ìƒì„± ì¤‘ë‹¨
  const stopGeneration = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }
    setIsGenerating(false);
  }, []);

  // íŒŒì¼ ì—…ë¡œë“œ
  const uploadFiles = async (files: File[]) => {
    const uploadPromises = files.map(async (file) => {
      const formData = new FormData();
      formData.append('file', file);
      
      const response = await apiClient.post('/files/upload', formData, {
        headers: { 'Content-Type': 'multipart/form-data' }
      });
      
      return response.data;
    });

    return Promise.all(uploadPromises);
  };

  return {
    messages,
    isGenerating,
    sendMessage: sendMessageMutation.mutate,
    sendStreamingMessage,
    stopGeneration,
    clearMessages,
    isLoading: sendMessageMutation.isPending
  };
};

// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
function generateId(): string {
  return `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}
```

---

## ğŸš€ **ìµœì‹  êµ¬í˜„ íŒ¨í„´ ì—…ë°ì´íŠ¸ (2025-08-19)**

### âœ… ì¸ë¼ì¸ UI êµ¬í˜„ íŒ¨í„´
```typescript
// ìƒˆë¡œìš´ ì¸ë¼ì¸ ChatInput êµ¬í˜„ íŒ¨í„´
interface InlineChatInputPattern {
  // íŒì—… ì œê±° â†’ ì¸ë¼ì¸ í†µí•©
  architecture: {
    elimination: "PopupAISettings ì»´í¬ë„ŒíŠ¸ ì™„ì „ ì œê±°",
    integration: "ChatInput ë‚´ë¶€ í†µí•© ë“œë¡­ë‹¤ìš´",
    benefits: ["UX ë‹¨ìˆœí™”", "ìƒíƒœ ê´€ë¦¬ ìµœì í™”", "ì ‘ê·¼ì„± í–¥ìƒ"]
  },
  
  // ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´ íŒ¨í„´
  model_dropdown: {
    positioning: "bottom-full mb-2 (ìƒí–¥ ì—´ë¦¼)",
    trigger: "Provider ì•„ì´ì½˜ + ê°„ì†Œí™”ëœ ëª¨ë¸ëª…",
    providers: {
      claude: "Star ì•„ì´ì½˜ (w-4 h-4 text-orange-500)",
      gemini: "Zap ì•„ì´ì½˜ (w-4 h-4 text-blue-500)"
    },
    responsive: "isMobile ? 'px-2 py-1' : 'px-3 py-1.5'"
  },
  
  // ê¸°ëŠ¥ í† ê¸€ ë²„íŠ¼ íŒ¨í„´
  feature_toggles: {
    layout: "flex space-x-1 (ìˆ˜í‰ ë°°ì¹˜)",
    position: "ëª¨ë¸ ë“œë¡­ë‹¤ìš´ ë‹¤ìŒ, íŒŒì¼ ì²¨ë¶€ ì•„ì´ì½˜ ì•",
    interaction: "ë‹¨ì¼ ì„ íƒ + ì¬í´ë¦­ í•´ì œ ë¡œì§",
    styling: {
      active: "bg-{color}-50 border-{color}-200 text-{color}-700",
      inactive: "bg-white border-slate-200 text-slate-600",
      hover: "hover:border-{color}-200 hover:bg-{color}-50"
    }
  }
}

// êµ¬í˜„ ì˜ˆì‹œ
const handleAgentToggle = (agentType: AgentType) => {
  if (selectedAgent === agentType) {
    onAgentChange('none'); // ê°™ì€ ë²„íŠ¼ í´ë¦­ì‹œ í•´ì œ
  } else {
    onAgentChange(agentType); // ë‹¤ë¥¸ ë²„íŠ¼ í´ë¦­ì‹œ ë³€ê²½
  }
};
```

### âœ… ë©”íƒ€ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬í˜„ íŒ¨í„´
```python
# 2ë‹¨ê³„ ë©”íƒ€ ê²€ìƒ‰ êµ¬í˜„ íŒ¨í„´
class MetaSearchImplementation:
    """ë©”íƒ€ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬í˜„ ê°€ì´ë“œ"""
    
    # 1ë‹¨ê³„: ëŒ€í™” ë§¥ë½ ë¶„ì„ ì„œë¹„ìŠ¤
    conversation_context_service = """
    # backend/app/services/conversation_context_service.py
    
    class ConversationContextService:
        async def analyze_context(self, conversation_id: str, user_query: str):
            # ì´ì „ ëŒ€í™” ë‚´ìš© ë¶„ì„
            previous_messages = await self.get_conversation_history(conversation_id)
            
            # ë§¥ë½ ì¶”ì¶œ
            context = await self.extract_conversation_context(previous_messages)
            
            # ì‚¬ìš©ì ì˜ë„ ë¶„ì„
            intent = await self.analyze_user_intent(user_query, context)
            
            return ContextAnalysis(
                previous_context=context,
                user_intent=intent,
                contextual_keywords=self.extract_keywords(context, user_query),
                temporal_context=self.extract_temporal_info(previous_messages)
            )
    """
    
    # 2ë‹¨ê³„: ì •ë³´ ë¶€ì¡± ë¶„ì„ê¸°
    information_gap_analyzer = """
    # backend/app/agents/workers/information_gap_analyzer.py
    
    class InformationGapAnalyzer:
        async def analyze(self, user_query: str, context: ContextAnalysis):
            gaps = []
            
            # ì‹œê°„ì  ì •ë³´ ë¶€ì¡± í™•ì¸
            if self.needs_temporal_info(user_query):
                gaps.append(InformationGap(
                    type='temporal',
                    field='time_range',
                    description='êµ¬ì²´ì ì¸ ì‹œê°„ ë²”ìœ„ê°€ í•„ìš”í•©ë‹ˆë‹¤',
                    urgency='high',
                    question='ì–¸ì œë¶€í„° ì–¸ì œê¹Œì§€ì˜ ì •ë³´ë¥¼ ì°¾ê³  ê³„ì‹ ê°€ìš”?'
                ))
            
            # ê³µê°„ì  ì •ë³´ ë¶€ì¡± í™•ì¸
            if self.needs_spatial_info(user_query):
                gaps.append(InformationGap(
                    type='spatial',
                    field='location',
                    description='ì§€ì—­ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤',
                    urgency='medium',
                    question='ì–´ëŠ ì§€ì—­ì˜ ì •ë³´ë¥¼ ì›í•˜ì‹œë‚˜ìš”?'
                ))
            
            return gaps
    """
    
    # 3ë‹¨ê³„: ì—ì´ì „íŠ¸ ì¶”ì²œ ì‹œìŠ¤í…œ
    agent_suggestion_modal = """
    # frontend/src/components/ui/AgentSuggestionModal.tsx
    
    interface AgentSuggestion {
      agent_type: AgentType;
      confidence: number;
      reason: string;
      capabilities: string[];
    }
    
    export const AgentSuggestionModal: React.FC<Props> = ({ suggestions, onSelect, onDismiss }) => {
      return (
        <Modal>
          <div className="p-6">
            <h3 className="text-lg font-semibold mb-4">ì¶”ì²œ AI ì—ì´ì „íŠ¸</h3>
            
            {suggestions.map((suggestion) => (
              <button
                key={suggestion.agent_type}
                onClick={() => onSelect(suggestion.agent_type)}
                className="w-full p-4 border rounded-lg hover:bg-gray-50 text-left mb-3"
              >
                <div className="flex items-center justify-between">
                  <div>
                    <h4 className="font-medium">{AGENT_TYPE_MAP[suggestion.agent_type].name}</h4>
                    <p className="text-sm text-gray-600 mt-1">{suggestion.reason}</p>
                  </div>
                  <div className="text-right">
                    <span className="text-sm text-green-600">{Math.round(suggestion.confidence * 100)}% ì í•©</span>
                  </div>
                </div>
              </button>
            ))}
          </div>
        </Modal>
      );
    };
    """
```

### âœ… Gemini 2.x ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ íŒ¨í„´
```typescript
// ì—…ê·¸ë ˆì´ë“œëœ ëª¨ë¸ íƒ€ì… ì‹œìŠ¤í…œ íŒ¨í„´
interface GeminiUpgradePattern {
  // ëª¨ë¸ íƒ€ì… ì •ì˜
  model_types: {
    'gemini-2.5-pro': {
      name: 'Gemini 2.5 Pro',
      description: 'ìµœì‹  ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸',
      capabilities: ['reasoning', 'multimodal', 'analysis', 'creative'],
      speed: 'medium',
      isRecommended: true
    },
    'gemini-2.5-flash': {
      name: 'Gemini 2.5 Flash', 
      description: 'ìµœì‹  ê³ ì† ë©€í‹°ëª¨ë‹¬ ëª¨ë¸',
      capabilities: ['reasoning', 'quick_tasks', 'multimodal'],
      speed: 'fast'
    },
    'gemini-2.0-pro': {
      name: 'Gemini 2.0 Pro',
      description: 'ì•ˆì •ì ì¸ ê³ ì„±ëŠ¥ ëª¨ë¸',
      capabilities: ['reasoning', 'analysis', 'multimodal'],
      speed: 'medium'
    },
    'gemini-2.0-flash': {
      name: 'Gemini 2.0 Flash',
      description: 'ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ëª¨ë¸',
      capabilities: ['reasoning', 'quick_tasks', 'multimodal'],
      speed: 'fast'
    }
  },
  
  // UI í‘œì‹œ íŒ¨í„´
  dropdown_display: {
    provider_icon: '<Zap className="w-3 h-3 text-blue-500" />',
    model_name_format: 'model.name.replace("Gemini ", "")', // "2.5 Pro" í˜•íƒœë¡œ í‘œì‹œ
    speed_indicator: 'model.speed === "fast" && <Zap className="w-3 h-3 text-green-500" />',
    recommended_badge: 'model.isRecommended && <Star className="w-3 h-3 text-amber-500" />'
  }
}
```

### ğŸ”§ ê°œë°œ ëª¨ë²” ì‚¬ë¡€ ì—…ë°ì´íŠ¸
1. **ì»´í¬ë„ŒíŠ¸ í†µí•© ì›ì¹™**: ê´€ë ¨ ê¸°ëŠ¥ì€ í•˜ë‚˜ì˜ ì»´í¬ë„ŒíŠ¸ì—ì„œ ê´€ë¦¬
2. **ìƒíƒœ ë™ê¸°í™” íŒ¨í„´**: Provider ë³€ê²½ ì‹œ ì²« ë²ˆì§¸ ëª¨ë¸ ìë™ ì„¤ì •
3. **ë°˜ì‘í˜• UI íŒ¨í„´**: isMobile ê¸°ë°˜ ì¡°ê±´ë¶€ ìŠ¤íƒ€ì¼ë§
4. **íƒ€ì… ì•ˆì „ì„±**: ëª¨ë“  ëª¨ë¸ ë° ì—ì´ì „íŠ¸ íƒ€ì… ì™„ì „ ì •ì˜

---

## ğŸ“ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ êµ¬í˜„ ê°€ì´ë“œë¼ì¸ (2025-08-20)

### ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜

#### ë°±ì—”ë“œ ì²­í‚¹ ì‹œìŠ¤í…œ
```python
def split_response_into_natural_chunks(response: str, chunk_size_range: tuple = (15, 40)) -> List[str]:
    """
    ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€ í…ìŠ¤íŠ¸ ë¶„í•  ì•Œê³ ë¦¬ì¦˜
    - 15-40ì í¬ê¸° ì²­í¬ë¡œ ë¶„í• 
    - ì¤„ë°”ê¿ˆ > ë¬¸ì¥ ë > ë‹¨ì–´ ê²½ê³„ ìš°ì„  ë¶„í• 
    - 100% ì›ë³¸ ë³´ì¡´ ë³´ì¥ (ì¬ê²°í•© ê²€ì¦)
    """
    if not response.strip():
        return []
    
    min_size, max_size = chunk_size_range
    chunks = []
    start = 0
    
    while start < len(response):
        chunk_end = start + max_size
        if chunk_end >= len(response):
            chunk_end = len(response)
        else:
            # ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• ì  ì°¾ê¸°
            text_segment = response[start:chunk_end + 20]
            
            # 1ìˆœìœ„: ì¤„ë°”ê¿ˆ
            newline_pos = text_segment.rfind('\n', min_size - start, max_size - start + 1)
            if newline_pos != -1:
                chunk_end = start + newline_pos + 1
            else:
                # 2ìˆœìœ„: ë¬¸ì¥ ë (.!?)
                sentence_pos = max(
                    text_segment.rfind('.', min_size - start, max_size - start + 1),
                    text_segment.rfind('!', min_size - start, max_size - start + 1),
                    text_segment.rfind('?', min_size - start, max_size - start + 1)
                )
                if sentence_pos != -1:
                    chunk_end = start + sentence_pos + 1
                else:
                    # 3ìˆœìœ„: ê³µë°± (ë‹¨ì–´ ê²½ê³„)
                    space_pos = text_segment.rfind(' ', min_size - start, max_size - start + 1)
                    if space_pos != -1:
                        chunk_end = start + space_pos
        
        chunk = response[start:chunk_end]
        if chunk:
            chunks.append(chunk)
        start = chunk_end
    
    # ì¬ê²°í•© ê²€ì¦ (100% ì •í™•ì„± ë³´ì¥)
    recombined = ''.join(chunks)
    if recombined != response:
        return [response]  # ì‹¤íŒ¨ ì‹œ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
    
    return chunks
```

#### í”„ë¡ íŠ¸ì—”ë“œ ì¦ë¶„ íŒŒì‹± ì‹œìŠ¤í…œ
```typescript
// ProgressiveMarkdown ì»´í¬ë„ŒíŠ¸ í•µì‹¬ ë¡œì§
const appendChunk = useCallback((chunk: string) => {
  // ìƒˆë¡œ ì¶”ê°€ëœ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ì²˜ë¦¬
  const newText = chunk.slice(incrementalState.lastProcessedLength);
  if (newText.length === 0) return;
  
  // ì¤„ë°”ê¿ˆ ê°ì§€ ë° ì™„ì„±ëœ ì¤„ê³¼ ì§„í–‰ ì¤‘ì¸ ì¤„ ë¶„ë¦¬
  const hasLineBreak = newText.includes('\n');
  
  setIncrementalState(prevState => {
    const newCompletedLines = [...prevState.completedLines];
    let newCurrentLine = prevState.currentLine;
    
    if (hasLineBreak) {
      const combinedText = prevState.currentLine + newText;
      const lines = combinedText.split('\n');
      
      // ë§ˆì§€ë§‰ ì¤„ì„ ì œì™¸í•œ ëª¨ë“  ì¤„ì€ ì™„ì„±ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
      for (let i = 0; i < lines.length - 1; i++) {
        const parsedLine: ParsedLine = {
          id: `line-${lineIdCounter.current++}`,
          element: parseMarkdownLine(lines[i], false),
          raw: lines[i],
          isComplete: true
        };
        newCompletedLines.push(parsedLine);
      }
      
      newCurrentLine = lines[lines.length - 1] || '';
    } else {
      newCurrentLine = prevState.currentLine + newText;
    }
    
    return {
      lastProcessedLength: chunk.length,
      completedLines: newCompletedLines,
      currentLine: newCurrentLine
    };
  });
}, []);
```

#### SSE ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œí† ì½œ
```typescript
// API ì„œë¹„ìŠ¤ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ì²˜ë¦¬
switch (eventData.type) {
  case 'chunk':
    // ì²­í¬ ë°ì´í„° ìˆ˜ì‹  - íƒ€ì´í•‘ íš¨ê³¼ë¡œ í‘œì‹œ
    const chunkData = eventData.data;
    console.log('ğŸ“ ì²­í¬ ìˆ˜ì‹ :', chunkData.text, '(ì¸ë±ìŠ¤:', chunkData.index, ')');
    onChunk(chunkData.text, chunkData.index === 0, chunkData.is_final);
    break;
    
  case 'result':
    console.log('ğŸ¯ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ - ìµœì¢… ê²°ê³¼ ìˆ˜ì‹ ');
    onResult(eventData.data);
    break;
    
  case 'error':
    console.error('âŒ ìŠ¤íŠ¸ë¦¬ë° ì—ëŸ¬:', eventData.data);
    onError(eventData.data.message);
    break;
}
```

### ì„±ëŠ¥ ìµœì í™” íŒ¨í„´

#### React ë Œë”ë§ ìµœì í™”
```typescript
// ê°œë³„ ì¤„ ë Œë”ëŸ¬ - React.memoë¡œ ë¶ˆí•„ìš”í•œ ë¦¬ë Œë”ë§ ë°©ì§€
const MemoizedLineRenderer = React.memo<MemoizedLineRendererProps>(({ line }) => {
  return <React.Fragment>{line.element}</React.Fragment>;
}, (prevProps, nextProps) => {
  // ì¤„ì˜ ë‚´ìš©ì´ ë™ì¼í•˜ë©´ ë¦¬ë Œë”ë§ í•˜ì§€ ì•ŠìŒ
  return prevProps.line.id === nextProps.line.id && 
         prevProps.line.raw === nextProps.line.raw &&
         prevProps.line.isComplete === nextProps.line.isComplete;
});
```

#### ì¸ë¼ì¸ ë§ˆí¬ë‹¤ìš´ íŒŒì‹± ìºì‹œ
```typescript
// ë©”ëª¨ì´ì œì´ì…˜ì„ ìœ„í•œ ìºì‹œ ì‹œìŠ¤í…œ
const parseInlineMarkdown = useMemo(() => {
  const cache = new Map<string, React.ReactNode>();
  
  return (text: string): React.ReactNode => {
    const cached = cache.get(text);
    if (cached !== undefined) return cached;
    
    // ë§ˆí¬ë‹¤ìš´ íŒŒì‹± ë¡œì§...
    const result = /* íŒŒì‹± ê²°ê³¼ */;
    
    // ìºì‹œì— ì €ì¥ (ìµœëŒ€ 100ê°œ í•­ëª©ë§Œ ìœ ì§€)
    if (cache.size > 100) {
      const firstKey = cache.keys().next().value;
      cache.delete(firstKey);
    }
    cache.set(text, result);
    
    return result;
  };
}, []);
```

---

**ë¬¸ì„œ ë²„ì „**: v2.1  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-08-20  
**ì‘ì„±ì**: AI í¬íƒˆ ê°œë°œíŒ€  
**ê²€í† ì**: ì‹œë‹ˆì–´ ê°œë°œì

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"id": "1", "content": "Context7\uc744 \ud1b5\ud55c \ucd5c\uc2e0 \uae30\uc220 \uc2a4\ud0dd \ubb38\uc11c \uc218\uc9d1 (React, FastAPI, LangGraph, WebSocket)", "status": "completed"}, {"id": "2", "content": "\uae30\uc874 SYGenai \uc2dc\uc2a4\ud15c \uad6c\uc870 \ubd84\uc11d \ubc0f \uc7ac\uc0ac\uc6a9 \uac00\ub2a5 \ud328\ud134 \uc2dd\ubcc4", "status": "completed"}, {"id": "3", "content": "\ud558\uc774\ube0c\ub9ac\ub4dc \uc544\ud0a4\ud14d\ucc98 \uc124\uacc4 - \uae30\uc874 \uc790\uc0b0 + \ud601\uc2e0 \uc694\uc18c \ud1b5\ud569", "status": "completed"}, {"id": "4", "content": "LLM \ub77c\uc6b0\ud305 \uc804\ub7b5 \uc218\uc815 - Claude/Gemini \ubaa8\ub378 \ud55c\uc815", "status": "completed"}, {"id": "5", "content": "Tier1 \ub3c4\uba54\uc778 \uc5d0\uc774\uc804\ud2b8 MCP \uc124\uc815 \uc2dc\uc2a4\ud15c \uc124\uacc4", "status": "completed"}, {"id": "6", "content": "\uc0c8\ubbf8 GPT \uae30\ub2a5 \ud1a0\uae00 \uc2dc\uc2a4\ud15c \uc124\uacc4", "status": "completed"}, {"id": "7", "content": "Redis \ub300\uccb4 \ubc29\uc548 \uac80\ud1a0 \ubc0f \uc124\uacc4", "status": "completed"}, {"id": "8", "content": "\uc0ac\uc6a9\uc790 \ud504\ub85c\ud30c\uc77c \uc790\ub3d9 \uc218\uc9d1 \uc2dc\uc2a4\ud15c \uc124\uacc4", "status": "completed"}, {"id": "9", "content": "develop.md \ucd5c\uc885 \uc5c5\ub370\uc774\ud2b8 - \ud1b5\ud569 \uac1c\ubc1c \uba85\uc138\uc11c \uc791\uc131", "status": "completed"}, {"id": "10", "content": "dev_plan.md \uc0c1\uc138 \uacc4\ud68d \uc218\ub9bd - 4\ub2e8\uacc4 10\uc8fc \uc2e4\ud589 \uacc4\ud68d", "status": "completed"}, {"id": "11", "content": "\uc544\ud0a4\ud14d\ucc98 \uc124\uacc4\uc11c \ubc0f \uad6c\ud604 \uac00\uc774\ub4dc\ub77c\uc778 \ubb38\uc11c\ud654", "status": "completed"}]