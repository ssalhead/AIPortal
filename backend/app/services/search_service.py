"""
ê²€ìƒ‰ ì„œë¹„ìŠ¤ - ì›¹ ê²€ìƒ‰ ë° ê²°ê³¼ ìºì‹±
"""

import asyncio
import hashlib
import json
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from urllib.parse import quote_plus
import httpx
from bs4 import BeautifulSoup
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings
from app.repositories.cache import CacheRepository
from app.services.cache_manager import cache_manager


class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        title: str,
        url: str,
        snippet: str,
        source: str = "web",
        score: float = 0.0,
        timestamp: str = None
    ):
        self.title = title
        self.url = url
        self.snippet = snippet
        self.source = source
        self.score = score
        self.timestamp = timestamp or datetime.utcnow().isoformat()
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "title": self.title,
            "url": self.url,
            "snippet": self.snippet,
            "source": self.source,
            "score": self.score,
            "timestamp": self.timestamp
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "SearchResult":
        return cls(
            title=data.get("title", ""),
            url=data.get("url", ""),
            snippet=data.get("snippet", ""),
            source=data.get("source", "web"),
            score=data.get("score", 0.0),
            timestamp=data.get("timestamp")
        )


class SearchService:
    """ê²€ìƒ‰ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(30.0),
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
        )
        self.cache_ttl = 3600  # 1ì‹œê°„ ìºì‹œ
    
    def _generate_cache_key(self, query: str, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        # ì¿¼ë¦¬ì™€ ì¶”ê°€ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°í•©í•˜ì—¬ ê³ ìœ  í‚¤ ìƒì„±
        key_data = {
            "query": query.lower().strip(),
            "source": kwargs.get("source", "web"),
            "max_results": kwargs.get("max_results", 5),
            "language": kwargs.get("language", "ko")
        }
        
        key_string = json.dumps(key_data, sort_keys=True)
        hash_key = hashlib.sha256(key_string.encode()).hexdigest()[:16]
        return f"search:{hash_key}"
    
    async def search_web_mock(
        self,
        query: str,
        max_results: int = 5,
        **kwargs
    ) -> List[SearchResult]:
        """Mock ì›¹ ê²€ìƒ‰ (API í‚¤ ì—†ì´ í…ŒìŠ¤íŠ¸ìš©)"""
        
        # ë‹¤ì–‘í•œ ì¿¼ë¦¬ë³„ Mock ê²°ê³¼
        mock_results = {
            "ai": [
                SearchResult(
                    title="ì¸ê³µì§€ëŠ¥(AI) ê¸°ìˆ  ë™í–¥ 2024",
                    url="https://example.com/ai-trends-2024",
                    snippet="2024ë…„ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ì£¼ìš” ë™í–¥ê³¼ ë°œì „ ë°©í–¥ì„ ì‚´í´ë´…ë‹ˆë‹¤. ìƒì„±í˜• AI, ë©€í‹°ëª¨ë‹¬ AI, ê·¸ë¦¬ê³  AIì˜ ì‹¤ìš©ì  í™œìš© ì‚¬ë¡€ë“¤ì„ ì†Œê°œí•©ë‹ˆë‹¤.",
                    source="tech_blog",
                    score=0.95
                ),
                SearchResult(
                    title="ChatGPTì™€ Claude AI ì„±ëŠ¥ ë¹„êµ",
                    url="https://example.com/llm-comparison",
                    snippet="ì£¼ìš” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ë‹¤ì–‘í•œ ì¸¡ë©´ì—ì„œ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ê³µê°œí•©ë‹ˆë‹¤. ê° ëª¨ë¸ì˜ ì¥ë‹¨ì ê³¼ ì ìš© ë¶„ì•¼ë³„ ì¶”ì²œì„ í™•ì¸í•´ë³´ì„¸ìš”.",
                    source="research_paper",
                    score=0.92
                )
            ],
            "python": [
                SearchResult(
                    title="Python 3.12 ìƒˆë¡œìš´ ê¸°ëŠ¥ ì™„ë²½ ê°€ì´ë“œ",
                    url="https://example.com/python-3-12-features",
                    snippet="Python 3.12ì—ì„œ ìƒˆë¡­ê²Œ ì¶”ê°€ëœ ê¸°ëŠ¥ë“¤ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤. ì„±ëŠ¥ ê°œì„ ì‚¬í•­, ìƒˆë¡œìš´ ë¬¸ë²•, ê·¸ë¦¬ê³  ê°œë°œìë“¤ì´ ì•Œì•„ì•¼ í•  ë³€ê²½ì ë“¤ì„ ë‹¤ë£¹ë‹ˆë‹¤.",
                    source="official_docs",
                    score=0.98
                ),
                SearchResult(
                    title="FastAPI vs Django 2024ë…„ ì„±ëŠ¥ ë¹„êµ",
                    url="https://example.com/fastapi-django-comparison",
                    snippet="ìµœì‹  Python ì›¹ í”„ë ˆì„ì›Œí¬ì¸ FastAPIì™€ ì „í†µì ì¸ Djangoì˜ ì„±ëŠ¥ì„ ì‹¤ì œ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë¹„êµ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
                    source="dev_community",
                    score=0.87
                )
            ],
            "ì›¹ê°œë°œ": [
                SearchResult(
                    title="2024 ì›¹ ê°œë°œ íŠ¸ë Œë“œì™€ ì „ë§",
                    url="https://example.com/web-dev-trends-2024",
                    snippet="2024ë…„ ì›¹ ê°œë°œ ë¶„ì•¼ì˜ ì£¼ìš” íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. React 18, Next.js 14, ê·¸ë¦¬ê³  ìƒˆë¡œìš´ ì›¹ ê¸°ìˆ ë“¤ì˜ ë°œì „ ë°©í–¥ì„ ì‚´í´ë´…ë‹ˆë‹¤.",
                    source="tech_magazine",
                    score=0.91
                )
            ]
        }
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ì„ í†µí•œ ê²°ê³¼ ë°˜í™˜
        results = []
        query_lower = query.lower()
        
        for keyword, search_results in mock_results.items():
            if keyword in query_lower or any(k in query_lower for k in keyword.split()):
                results.extend(search_results)
        
        # ê¸°ë³¸ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ Mock ê²°ê³¼ ìƒì„±
        if not results:
            results = [
                SearchResult(
                    title=f"'{query}' ê´€ë ¨ ìµœì‹  ì •ë³´",
                    url=f"https://example.com/search?q={quote_plus(query)}",
                    snippet=f"'{query}'ì— ëŒ€í•œ ìƒì„¸í•œ ì •ë³´ì™€ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ìµœì‹  ë™í–¥ê³¼ ì‹¤ìš©ì ì¸ í™œìš© ë°©ë²•ì„ í™•ì¸í•´ë³´ì„¸ìš”.",
                    source="search_engine",
                    score=0.85
                ),
                SearchResult(
                    title=f"{query} - ì¢…í•© ê°€ì´ë“œ",
                    url=f"https://example.com/guide/{quote_plus(query)}",
                    snippet=f"{query}ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì´ë“œì…ë‹ˆë‹¤. ê¸°ì´ˆë¶€í„° ê³ ê¸‰ í™œìš©ë²•ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.",
                    source="documentation",
                    score=0.78
                )
            ]
        
        # max_results ì œí•œ ì ìš©
        return results[:max_results]
    
    async def search_duckduckgo(
        self,
        query: str,
        max_results: int = 5,
        **kwargs
    ) -> List[SearchResult]:
        """DuckDuckGo ê²€ìƒ‰ (API í‚¤ ë¶ˆí•„ìš”)"""
        try:
            # DuckDuckGo Instant Answer API ì‚¬ìš©
            url = "https://api.duckduckgo.com/"
            params = {
                "q": query,
                "format": "json",
                "no_html": "1",
                "skip_disambig": "1"
            }
            
            response = await self.client.get(url, params=params)
            response.raise_for_status()
            
            data = response.json()
            results = []
            
            # Abstract ì •ë³´
            if data.get("Abstract"):
                results.append(SearchResult(
                    title=data.get("Heading", query),
                    url=data.get("AbstractURL", ""),
                    snippet=data["Abstract"],
                    source="duckduckgo_abstract",
                    score=0.95
                ))
            
            # Definition ì •ë³´ (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
            if data.get("Definition"):
                results.append(SearchResult(
                    title=data.get("Definition", {}).get("Source", query),
                    url=data.get("Definition", {}).get("FirstURL", ""),
                    snippet=data.get("Definition", {}).get("Text", ""),
                    source="duckduckgo_definition",
                    score=0.93
                ))
            
            # Related topics
            for topic in data.get("RelatedTopics", [])[:max_results-len(results)]:
                if isinstance(topic, dict) and "Text" in topic:
                    results.append(SearchResult(
                        title=topic.get("Result", "").split(" - ")[0] if " - " in topic.get("Result", "") else query,
                        url=topic.get("FirstURL", ""),
                        snippet=topic["Text"],
                        source="duckduckgo_topic",
                        score=0.80
                    ))
            
            return results[:max_results]
            
        except Exception as e:
            print(f"DuckDuckGo ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def search_google(
        self,
        query: str,
        max_results: int = 5,
        **kwargs
    ) -> List[SearchResult]:
        """Google Custom Search APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰"""
        
        if not settings.GOOGLE_API_KEY or not settings.GOOGLE_CSE_ID:
            print("Google API í‚¤ ë˜ëŠ” CSE IDê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return []
        
        try:
            url = "https://www.googleapis.com/customsearch/v1"
            params = {
                "key": settings.GOOGLE_API_KEY,
                "cx": settings.GOOGLE_CSE_ID,
                "q": query,
                "num": min(max_results, 10),  # Google APIëŠ” ìµœëŒ€ 10ê°œê¹Œì§€
                "hl": kwargs.get("language", "ko"),  # í•œêµ­ì–´ ì¸í„°í˜ì´ìŠ¤
                "safe": "medium"  # SafeSearch ì¤‘ê°„ ìˆ˜ì¤€
                # searchType ì œê±° - ê¸°ë³¸ê°’ì´ ì›¹ ê²€ìƒ‰
            }
            
            response = await self.client.get(url, params=params, timeout=10.0)
            response.raise_for_status()
            
            data = response.json()
            results = []
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì¡°ê¸° ë°˜í™˜
            if "items" not in data:
                print(f"Google ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {query}")
                return []
            
            # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
            items = data.get("items", [])
            for item in items[:max_results]:
                # URL ê²€ì¦ (ìœ íš¨í•œ HTTP/HTTPS URLì¸ì§€ í™•ì¸)
                link = item.get("link", "")
                if not link.startswith(("http://", "https://")):
                    continue
                
                result = SearchResult(
                    title=item.get("title", "").strip(),
                    url=link,
                    snippet=item.get("snippet", "").strip(),
                    source=f"google_{item.get('displayLink', 'unknown')}",
                    score=0.9 - (len(results) * 0.05)  # ìˆœì„œì— ë”°ë¥¸ ì ìˆ˜
                )
                
                # ë¹ˆ ì œëª©ì´ë‚˜ ìŠ¤ë‹ˆí«ì´ ìˆëŠ” ê²°ê³¼ í•„í„°ë§
                if result.title and result.snippet:
                    results.append(result)
            
            print(f"Google ê²€ìƒ‰ ì™„ë£Œ: {query} -> {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except httpx.TimeoutException:
            print(f"Google ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
            return []
        except httpx.HTTPStatusError as e:
            print(f"Google ê²€ìƒ‰ HTTP ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
            return []
        except Exception as e:
            print(f"Google ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def search_web(
        self,
        query: str,
        max_results: int = 5,
        use_cache: bool = True,
        session: Optional[AsyncSession] = None,
        **kwargs
    ) -> List[SearchResult]:
        """
        ì›¹ ê²€ìƒ‰ ì‹¤í–‰ (ìºì‹œ ì§€ì›)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
            session: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            **kwargs: ì¶”ê°€ ê²€ìƒ‰ ì˜µì…˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        cache_key = self._generate_cache_key(query, max_results=max_results, **kwargs)
        
        # ìºì‹œ í™•ì¸
        if use_cache:
            cached_results = await cache_manager.get(cache_key, session)
            if cached_results:
                print(f"ìºì‹œì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ: {query}")
                return [SearchResult.from_dict(result) for result in cached_results]
        
        # ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
        results = []
        
        try:
            # 1. DuckDuckGoë¥¼ ë©”ì¸ ê²€ìƒ‰ ì—”ì§„ìœ¼ë¡œ ì‚¬ìš© (ì•ˆì •ì ì´ê³  ë¬´ë£Œ)
            duckduckgo_results = await self.search_duckduckgo(query, max_results, **kwargs)
            results.extend(duckduckgo_results)
            print(f"DuckDuckGo ê²€ìƒ‰ ê²°ê³¼: {len(duckduckgo_results)}ê°œ")
            
            # 2. Google Custom Searchë¡œ ì¶”ê°€ ê²°ê³¼ ë³´ì™„ (ì„¤ì •ëœ ê²½ìš°ì—ë§Œ)
            if len(results) < max_results and settings.GOOGLE_API_KEY and settings.GOOGLE_CSE_ID:
                remaining = max_results - len(results)
                try:
                    google_results = await self.search_google(query, remaining, **kwargs)
                    results.extend(google_results)
                    print(f"Google ê²€ìƒ‰ ì¶”ê°€ ê²°ê³¼: {len(google_results)}ê°œ")
                except Exception as google_error:
                    print(f"Google ê²€ìƒ‰ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {google_error}")
            
        except Exception as e:
            print(f"ì‹¤ì œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            # Googleê³¼ DuckDuckGo ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ Mock ê²€ìƒ‰ ì‹œë„
            try:
                mock_results = await self.search_web_mock(query, max_results, **kwargs)
                results.extend(mock_results)
                print(f"Mock ê²€ìƒ‰ ê²°ê³¼ë¡œ ëŒ€ì²´: {len(mock_results)}ê°œ")
            except Exception as mock_error:
                print(f"Mock ê²€ìƒ‰ë„ ì‹¤íŒ¨: {mock_error}")
        
        # 2. ëª¨ë“  ì‹¤ì œ ê²€ìƒ‰ì´ ì‹¤íŒ¨í–ˆì„ ë•Œë§Œ Mock ê²°ê³¼ ì‚¬ìš©
        if not results:
            print("ëª¨ë“  ì‹¤ì œ ê²€ìƒ‰ ì‹¤íŒ¨ - Mock ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©")
            mock_results = await self.search_web_mock(query, max_results, **kwargs)
            results.extend(mock_results)
        
        # 3. ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìºì‹œì— ì €ì¥
        if results and use_cache and session:
            cache_data = [result.to_dict() for result in results]
            await cache_manager.set(cache_key, cache_data, session, ttl_seconds=self.cache_ttl)
            print(f"ê²€ìƒ‰ ê²°ê³¼ ìºì‹œì— ì €ì¥: {query} ({len(results)}ê°œ ê²°ê³¼)")
        
        return results[:max_results]
    
    async def get_search_suggestions(self, query: str) -> List[str]:
        """ê²€ìƒ‰ ì œì•ˆì–´ ìƒì„±"""
        suggestions = []
        
        # ì¿¼ë¦¬ ê¸°ë°˜ ì œì•ˆì–´ ìƒì„±
        base_suggestions = [
            f"{query} ì‚¬ìš©ë²•",
            f"{query} ì˜ˆì œ",
            f"{query} íŠœí† ë¦¬ì–¼",
            f"{query} ìµœì‹  ë™í–¥",
            f"{query} vs"
        ]
        
        # í”„ë¡œê·¸ë˜ë° ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€
        programming_keywords = ["python", "javascript", "react", "api", "database", "ì›¹ê°œë°œ", "ì•±ê°œë°œ"]
        if any(keyword in query.lower() for keyword in programming_keywords):
            suggestions.extend([
                f"{query} ë¼ì´ë¸ŒëŸ¬ë¦¬",
                f"{query} í”„ë ˆì„ì›Œí¬",
                f"{query} ì—ëŸ¬ í•´ê²°",
                f"{query} ì„±ëŠ¥ ìµœì í™”"
            ])
        
        # AI ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€
        ai_keywords = ["ai", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "llm", "chatgpt", "claude"]
        if any(keyword in query.lower() for keyword in ai_keywords):
            suggestions.extend([
                f"{query} ëª¨ë¸",
                f"{query} í™œìš© ì‚¬ë¡€",
                f"{query} í”„ë¡¬í”„íŠ¸",
                f"{query} í•œê³„"
            ])
        
        return suggestions[:5]
    
    async def summarize_results(
        self,
        query: str,
        results: List[SearchResult],
        session: Optional[AsyncSession] = None
    ) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½"""
        if not results:
            return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ê²°ê³¼ ìš”ì•½ ìƒì„±
        summary_parts = [
            f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):\n"
        ]
        
        for i, result in enumerate(results, 1):
            summary_parts.append(
                f"{i}. **{result.title}**\n"
                f"   {result.snippet[:150]}{'...' if len(result.snippet) > 150 else ''}\n"
                f"   ğŸ”— {result.url}\n"
                f"   ğŸ“Š ì¶œì²˜: {result.source} | ì‹ ë¢°ë„: {result.score:.0%}\n"
            )
        
        summary = "\n".join(summary_parts)
        
        # ìš”ì•½ë„ ìºì‹œì— ì €ì¥
        if session:
            cache_key = f"summary:{self._generate_cache_key(query)}"
            await cache_manager.set(cache_key, summary, session, ttl_seconds=self.cache_ttl)
        
        return summary
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬"""
        await self.client.aclose()


# ì „ì—­ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
search_service = SearchService()