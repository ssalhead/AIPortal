"""
LangGraph ê¸°ë°˜ Canvas ì—ì´ì „íŠ¸ - ì™„ì „í•œ ì‹œê°í™” ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œ

ê¸°ì¡´ Canvas ì—ì´ì „íŠ¸ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ LangGraph StateGraphë¡œ ì¬êµ¬í˜„í•œ ê³ ì„±ëŠ¥ ë²„ì „ì…ë‹ˆë‹¤.
ìš´ì˜ ì¤‘ë‹¨ ì œì•½ ì—†ì´ ìµœì í™”ëœ ë©€í‹°ëª¨ë‹¬ Canvas ìƒì„± ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import time
import asyncio
import json
import uuid
from typing import Dict, Any, List, Optional, TypedDict, Union
from datetime import datetime
import logging

# LangGraph í•µì‹¬ imports
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.postgres import PostgresSaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# ê¸°ì¡´ ì‹œìŠ¤í…œ imports
from app.agents.base import BaseAgent, AgentInput, AgentOutput
from app.agents.workers.canvas import CanvasAgent
from app.services.image_generation_service import image_generation_service
from app.services.canvas_workflow_dispatcher import (
    CanvasWorkflowDispatcher, 
    ImageGenerationRequest, 
    RequestSource,
    WorkflowMode
)
from app.core.config import settings
from app.core.feature_flags import is_langgraph_enabled, LangGraphFeatureFlags
from app.services.langgraph_monitor import langgraph_monitor

logger = logging.getLogger(__name__)


class CanvasState(TypedDict):
    """LangGraph Canvas ìƒíƒœ ì •ì˜"""
    # ì…ë ¥ ë°ì´í„°
    original_query: str
    user_id: str
    conversation_id: Optional[str]
    session_id: Optional[str]
    model: str
    
    # ë¶„ì„ ë‹¨ê³„
    canvas_analysis: Optional[Dict[str, Any]]
    canvas_type: Optional[str]
    content_requirements: Optional[Dict[str, Any]]
    
    # ìƒì„± ì „ëµ ìˆ˜ë¦½
    generation_strategy: Optional[Dict[str, Any]]
    workflow_plan: Optional[List[Dict[str, Any]]]
    
    # ì½˜í…ì¸  ìƒì„±
    generated_content: Optional[Dict[str, Any]]
    visual_elements: Optional[List[Dict[str, Any]]]
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬
    image_requests: Optional[List[Dict[str, Any]]]
    generated_images: Optional[List[Dict[str, Any]]]
    
    # í†µí•© ë° ìµœì í™”
    canvas_data: Optional[Dict[str, Any]]
    optimization_results: Optional[Dict[str, Any]]
    final_canvas: Optional[Dict[str, Any]]
    
    # ë©”íƒ€ë°ì´í„°
    execution_metadata: Dict[str, Any]
    performance_metrics: Dict[str, Any]
    
    # ì—ëŸ¬ ì²˜ë¦¬
    errors: List[str]
    should_fallback: bool


class LangGraphCanvasAgent(BaseAgent):
    """LangGraph ê¸°ë°˜ Canvas ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            agent_id="langgraph_canvas",
            name="LangGraph Canvas ì—ì´ì „íŠ¸",
            description="LangGraph StateGraphë¡œ êµ¬í˜„ëœ ê³ ê¸‰ ì‹œê°í™” ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œ"
        )
        
        # ë ˆê±°ì‹œ ì—ì´ì „íŠ¸ (fallbackìš© - ìš´ì˜ì¤‘ì´ ì•„ë‹ˆë¯€ë¡œ ì œê±° ì˜ˆì •)
        self.legacy_agent = CanvasAgent()
        
        # Canvas ì›Œí¬í”Œë¡œìš° ë””ìŠ¤íŒ¨ì²˜
        self.workflow_dispatcher = CanvasWorkflowDispatcher()
        
        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        self.workflow = self._build_workflow()
        
        # PostgreSQL ì²´í¬í¬ì¸í„° ì„¤ì •
        if settings.DATABASE_URL:
            self.checkpointer = PostgresSaver.from_conn_string(
                settings.DATABASE_URL,
                
            )
        else:
            self.checkpointer = None
            logger.warning("DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ - ì²´í¬í¬ì¸í„° ë¹„í™œì„±í™”")

    def _build_workflow(self) -> StateGraph:
        """LangGraph Canvas ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        
        # StateGraph ìƒì„±
        workflow = StateGraph(CanvasState)
        
        # ë…¸ë“œ ì •ì˜ - 7ë‹¨ê³„ ê³ ë„í™”ëœ íŒŒì´í”„ë¼ì¸
        workflow.add_node("analyze_canvas_request", self._analyze_canvas_request_node)
        workflow.add_node("develop_generation_strategy", self._develop_generation_strategy_node)
        workflow.add_node("generate_content_structure", self._generate_content_structure_node)
        workflow.add_node("process_image_generation", self._process_image_generation_node)
        workflow.add_node("create_visual_elements", self._create_visual_elements_node)
        workflow.add_node("integrate_and_optimize", self._integrate_and_optimize_node)
        workflow.add_node("finalize_canvas", self._finalize_canvas_node)
        
        # ì—£ì§€ ì •ì˜ - ì„ í˜• íŒŒì´í”„ë¼ì¸
        workflow.set_entry_point("analyze_canvas_request")
        workflow.add_edge("analyze_canvas_request", "develop_generation_strategy")
        workflow.add_edge("develop_generation_strategy", "generate_content_structure")
        workflow.add_edge("generate_content_structure", "process_image_generation")
        workflow.add_edge("process_image_generation", "create_visual_elements")
        workflow.add_edge("create_visual_elements", "integrate_and_optimize")
        workflow.add_edge("integrate_and_optimize", "finalize_canvas")
        workflow.add_edge("finalize_canvas", END)
        
        # ì¡°ê±´ë¶€ ì—£ì§€ (ë³‘ë ¬ ì²˜ë¦¬ ë¶„ê¸°ì )
        workflow.add_conditional_edges(
            "analyze_canvas_request",
            self._should_continue,
            {
                "continue": "develop_generation_strategy",
                "fallback": END
            }
        )
        
        return workflow

    async def _analyze_canvas_request_node(self, state: CanvasState) -> Dict[str, Any]:
        """Canvas ìš”ì²­ ë¶„ì„ ë…¸ë“œ - ì§€ëŠ¥í˜• ì˜ë„ íŒŒì•…"""
        try:
            logger.info(f"ğŸ¨ LangGraph Canvas: ìš”ì²­ ë¶„ì„ ì¤‘... (query: {state['original_query'][:50]})")
            
            model = self._get_llm_model(state["model"])
            
            analysis_prompt = ChatPromptTemplate.from_messages([
                ("system", """ë‹¹ì‹ ì€ ì „ë¬¸ Canvas ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì‹œê°í™” ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

ë¶„ì„í•´ì•¼ í•  í•­ëª©:
1. Canvas íƒ€ì… ê²°ì • (ì´ë¯¸ì§€ìƒì„±/ë§ˆì¸ë“œë§µ/í”Œë¡œìš°ì°¨íŠ¸/ë‹¤ì´ì–´ê·¸ë¨/ì°¨íŠ¸/í…Œì´ë¸”/ê¸°íƒ€)
2. ë³µì¡ë„ ë ˆë²¨ (ê°„ë‹¨/ë³´í†µ/ë³µì¡/ê³ ê¸‰)
3. í•„ìš”í•œ ì‹œê°ì  ìš”ì†Œë“¤
4. ìƒì„± ìš°ì„ ìˆœìœ„
5. ë©€í‹°ëª¨ë‹¬ ìš”êµ¬ì‚¬í•­

JSON í˜•ì‹ìœ¼ë¡œ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”."""),
                ("human", """ìš”ì²­: "{query}"

ì´ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ Canvas ìƒì„± ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.""")
            ])
            
            response = await model.ainvoke(analysis_prompt.format_messages(query=state["original_query"]))
            
            try:
                canvas_analysis = json.loads(response.content)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„
                canvas_analysis = {
                    "canvas_type": self._determine_canvas_type_fallback(state["original_query"]),
                    "complexity": "ë³´í†µ",
                    "visual_elements": ["í…ìŠ¤íŠ¸", "ê¸°ë³¸ ë„í˜•"],
                    "priority": "ë†’ìŒ",
                    "multimodal_requirements": ["ì‹œê°í™”"]
                }
            
            # Canvas íƒ€ì… í™•ì •
            canvas_type = canvas_analysis.get("canvas_type", "ë‹¤ì´ì–´ê·¸ë¨")
            
            # ì½˜í…ì¸  ìš”êµ¬ì‚¬í•­ ì •ì˜
            content_requirements = {
                "primary_type": canvas_type,
                "complexity_level": canvas_analysis.get("complexity", "ë³´í†µ"),
                "visual_elements": canvas_analysis.get("visual_elements", []),
                "interactive_features": canvas_analysis.get("interactive_features", []),
                "color_scheme": canvas_analysis.get("color_scheme", "ê¸°ë³¸"),
                "size_requirements": canvas_analysis.get("size_requirements", "í‘œì¤€")
            }
            
            return {
                "canvas_analysis": canvas_analysis,
                "canvas_type": canvas_type,
                "content_requirements": content_requirements,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "analysis_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Canvas ìš”ì²­ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "errors": state.get("errors", []) + [f"Canvas ë¶„ì„ ì‹¤íŒ¨: {str(e)}"],
                "should_fallback": True
            }

    async def _develop_generation_strategy_node(self, state: CanvasState) -> Dict[str, Any]:
        """ìƒì„± ì „ëµ ìˆ˜ë¦½ ë…¸ë“œ - ìµœì í™”ëœ ìƒì„± ê³„íš"""
        try:
            logger.info(f"ğŸ¨ LangGraph Canvas: ìƒì„± ì „ëµ ìˆ˜ë¦½ ì¤‘... (íƒ€ì…: {state['canvas_type']})")
            
            model = self._get_llm_model(state["model"])
            canvas_type = state["canvas_type"]
            requirements = state["content_requirements"]
            
            strategy_prompt = ChatPromptTemplate.from_messages([
                ("system", """Canvas ìƒì„± ì „ë¬¸ê°€ë¡œì„œ ìµœì í™”ëœ ìƒì„± ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

ì „ëµ ìš”ì†Œ:
1. ìƒì„± ìˆœì„œ ìµœì í™” (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥ ì˜ì—­ ì‹ë³„)
2. ë¦¬ì†ŒìŠ¤ í• ë‹¹ ê³„íš
3. í’ˆì§ˆ ë³´ì¦ ì²´í¬í¬ì¸íŠ¸
4. ì„±ëŠ¥ ìµœì í™” í¬ì¸íŠ¸
5. ì‚¬ìš©ì ê²½í—˜ ìµœì í™”

JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšì„ ì œê³µí•˜ì„¸ìš”."""),
                ("human", """Canvas íƒ€ì…: {canvas_type}
ìš”êµ¬ì‚¬í•­: {requirements}

ìµœì ì˜ ìƒì„± ì „ëµê³¼ ì›Œí¬í”Œë¡œìš° ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.""")
            ])
            
            response = await model.ainvoke(strategy_prompt.format_messages(
                canvas_type=canvas_type,
                requirements=json.dumps(requirements, ensure_ascii=False, indent=2)
            ))
            
            try:
                generation_strategy = json.loads(response.content)
            except json.JSONDecodeError:
                # ê¸°ë³¸ ì „ëµ
                generation_strategy = {
                    "approach": "ë‹¨ê³„ë³„_ìˆœì°¨_ìƒì„±",
                    "parallel_tasks": [],
                    "quality_checkpoints": ["ì¤‘ê°„_ê²€í† ", "ìµœì¢…_ê²€ì¦"],
                    "optimization_targets": ["í’ˆì§ˆ", "ì†ë„"]
                }
            
            # ì›Œí¬í”Œë¡œìš° ê³„íš ìƒì„±
            workflow_plan = self._create_workflow_plan(canvas_type, generation_strategy)
            
            return {
                "generation_strategy": generation_strategy,
                "workflow_plan": workflow_plan,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "strategy_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ìƒì„± ì „ëµ ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            return {
                "errors": state.get("errors", []) + [f"ì „ëµ ìˆ˜ë¦½ ì‹¤íŒ¨: {str(e)}"]
            }

    async def _generate_content_structure_node(self, state: CanvasState) -> Dict[str, Any]:
        """ì½˜í…ì¸  êµ¬ì¡° ìƒì„± ë…¸ë“œ - ì‹¤ì œ Canvas ì½˜í…ì¸  ìƒì„±"""
        try:
            logger.info("ğŸ¨ LangGraph Canvas: ì½˜í…ì¸  êµ¬ì¡° ìƒì„± ì¤‘...")
            
            model = self._get_llm_model(state["model"])
            canvas_type = state["canvas_type"]
            
            # Canvas íƒ€ì…ë³„ íŠ¹í™”ëœ ì½˜í…ì¸  ìƒì„±
            if canvas_type == "ì´ë¯¸ì§€":
                # ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì¤€ë¹„
                generated_content = await self._prepare_image_generation(state)
            elif canvas_type == "ë§ˆì¸ë“œë§µ":
                generated_content = await self._generate_mindmap_content(state, model)
            elif canvas_type == "í”Œë¡œìš°ì°¨íŠ¸":
                generated_content = await self._generate_flowchart_content(state, model)
            elif canvas_type == "ì°¨íŠ¸":
                generated_content = await self._generate_chart_content(state, model)
            else:
                generated_content = await self._generate_generic_canvas_content(state, model)
            
            # ì‹œê°ì  ìš”ì†Œ ì •ì˜
            visual_elements = self._define_visual_elements(generated_content, canvas_type)
            
            return {
                "generated_content": generated_content,
                "visual_elements": visual_elements,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "content_generated_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ì½˜í…ì¸  êµ¬ì¡° ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "errors": state.get("errors", []) + [f"ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {str(e)}"]
            }

    async def _process_image_generation_node(self, state: CanvasState) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬ ë…¸ë“œ - ê³ ì„±ëŠ¥ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            logger.info("ğŸ¨ LangGraph Canvas: ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬ ì¤‘...")
            
            generated_images = []
            image_requests = state.get("image_requests", [])
            
            if image_requests:
                # ë³‘ë ¬ ì´ë¯¸ì§€ ìƒì„± (ìš´ì˜ ì¤‘ë‹¨ ì œì•½ ì—†ìœ¼ë¯€ë¡œ ê³µê²©ì  ìµœì í™”)
                image_tasks = []
                for request in image_requests:
                    task = self._generate_single_image(request, state)
                    image_tasks.append(task)
                
                # ëª¨ë“  ì´ë¯¸ì§€ ë³‘ë ¬ ìƒì„±
                results = await asyncio.gather(*image_tasks, return_exceptions=True)
                
                for result in results:
                    if isinstance(result, Exception):
                        logger.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {result}")
                    else:
                        generated_images.append(result)
            
            return {
                "generated_images": generated_images,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "image_processing_completed_at": time.time(),
                    "images_generated_count": len(generated_images)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "errors": state.get("errors", []) + [f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}"]
            }

    async def _create_visual_elements_node(self, state: CanvasState) -> Dict[str, Any]:
        """ì‹œê°ì  ìš”ì†Œ ìƒì„± ë…¸ë“œ - ê³ ê¸‰ ì‹œê°í™”"""
        try:
            logger.info("ğŸ¨ LangGraph Canvas: ì‹œê°ì  ìš”ì†Œ ìƒì„± ì¤‘...")
            
            # ì‹œê°ì  ìš”ì†Œ ìµœì í™” ë° ë°°ì¹˜
            visual_elements = state.get("visual_elements", [])
            optimized_elements = []
            
            for element in visual_elements:
                optimized_element = self._optimize_visual_element(element)
                optimized_elements.append(optimized_element)
            
            return {
                "visual_elements": optimized_elements,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "visual_elements_created_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ì‹œê°ì  ìš”ì†Œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "errors": state.get("errors", []) + [f"ì‹œê°ì  ìš”ì†Œ ìƒì„± ì‹¤íŒ¨: {str(e)}"]
            }

    async def _integrate_and_optimize_node(self, state: CanvasState) -> Dict[str, Any]:
        """í†µí•© ë° ìµœì í™” ë…¸ë“œ - ì„±ëŠ¥ ìµœì í™”"""
        try:
            logger.info("ğŸ¨ LangGraph Canvas: í†µí•© ë° ìµœì í™” ì¤‘...")
            
            # Canvas ë°ì´í„° í†µí•©
            canvas_data = self._integrate_canvas_data(
                content=state.get("generated_content", {}),
                visual_elements=state.get("visual_elements", []),
                images=state.get("generated_images", []),
                canvas_type=state["canvas_type"]
            )
            
            # ì„±ëŠ¥ ìµœì í™”
            optimization_results = self._optimize_canvas_performance(canvas_data)
            
            return {
                "canvas_data": canvas_data,
                "optimization_results": optimization_results,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "integration_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© ë° ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "errors": state.get("errors", []) + [f"í†µí•© ìµœì í™” ì‹¤íŒ¨: {str(e)}"]
            }

    async def _finalize_canvas_node(self, state: CanvasState) -> Dict[str, Any]:
        """Canvas ìµœì¢…í™” ë…¸ë“œ - ì™„ì„± ë° ê²€ì¦"""
        try:
            logger.info("ğŸ¨ LangGraph Canvas: ìµœì¢…í™” ì²˜ë¦¬ ì¤‘...")
            
            # ìµœì¢… Canvas êµ¬ì„±
            final_canvas = {
                "type": state["canvas_type"],
                "data": state.get("canvas_data", {}),
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "optimization": state.get("optimization_results", {}),
                    "performance_score": self._calculate_performance_score(state)
                }
            }
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
            start_time = state.get("execution_metadata", {}).get("analysis_completed_at", time.time())
            total_execution_time = time.time() - start_time
            
            performance_metrics = {
                "total_execution_time_ms": int(total_execution_time * 1000),
                "analysis_time_ms": int((state.get("execution_metadata", {}).get("strategy_completed_at", 0) - start_time) * 1000) if state.get("execution_metadata", {}).get("strategy_completed_at") else 0,
                "generation_time_ms": int((state.get("execution_metadata", {}).get("content_generated_at", 0) - state.get("execution_metadata", {}).get("strategy_completed_at", 0)) * 1000) if all([
                    state.get("execution_metadata", {}).get("content_generated_at"),
                    state.get("execution_metadata", {}).get("strategy_completed_at")
                ]) else 0,
                "optimization_time_ms": int((state.get("execution_metadata", {}).get("integration_completed_at", 0) - state.get("execution_metadata", {}).get("visual_elements_created_at", 0)) * 1000) if all([
                    state.get("execution_metadata", {}).get("integration_completed_at"),
                    state.get("execution_metadata", {}).get("visual_elements_created_at")
                ]) else 0,
                "images_count": len(state.get("generated_images", [])),
                "visual_elements_count": len(state.get("visual_elements", [])),
                "quality_score": self._calculate_quality_score(state)
            }
            
            return {
                "final_canvas": final_canvas,
                "performance_metrics": performance_metrics,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "finalization_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Canvas ìµœì¢…í™” ì‹¤íŒ¨: {e}")
            return {
                "errors": state.get("errors", []) + [f"ìµœì¢…í™” ì‹¤íŒ¨: {str(e)}"]
            }

    def _should_continue(self, state: CanvasState) -> str:
        """ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜"""
        if state.get("should_fallback", False) or len(state.get("errors", [])) > 3:
            return "fallback"
        return "continue"

    def _get_llm_model(self, model_name: str):
        """LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if "claude" in model_name.lower():
            return ChatAnthropic(
                model_name=model_name,
                anthropic_api_key=settings.ANTHROPIC_API_KEY,
                temperature=0.4
            )
        elif "gemini" in model_name.lower():
            return ChatGoogleGenerativeAI(
                model=model_name,
                google_api_key=settings.GOOGLE_API_KEY,
                temperature=0.4
            )
        else:
            return ChatAnthropic(
                model_name="claude-3-sonnet-20240229",
                anthropic_api_key=settings.ANTHROPIC_API_KEY,
                temperature=0.4
            )

    def _determine_canvas_type_fallback(self, query: str) -> str:
        """ê¸°ë³¸ Canvas íƒ€ì… ê²°ì • (fallback)"""
        query_lower = query.lower()
        if any(word in query_lower for word in ["ê·¸ë ¤", "ë§Œë“¤ì–´", "ìƒì„±", "ì´ë¯¸ì§€", "ê·¸ë¦¼"]):
            return "ì´ë¯¸ì§€"
        elif any(word in query_lower for word in ["ë§ˆì¸ë“œë§µ", "mindmap", "ê°œë…ë„"]):
            return "ë§ˆì¸ë“œë§µ"
        elif any(word in query_lower for word in ["í”Œë¡œìš°ì°¨íŠ¸", "flowchart", "íë¦„ë„"]):
            return "í”Œë¡œìš°ì°¨íŠ¸"
        elif any(word in query_lower for word in ["ì°¨íŠ¸", "ê·¸ë˜í”„", "chart"]):
            return "ì°¨íŠ¸"
        else:
            return "ë‹¤ì´ì–´ê·¸ë¨"

    def _create_workflow_plan(self, canvas_type: str, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì›Œí¬í”Œë¡œìš° ê³„íš ìƒì„±"""
        return [
            {"step": "content_analysis", "priority": 1, "parallel": False},
            {"step": "structure_generation", "priority": 2, "parallel": True},
            {"step": "visual_creation", "priority": 3, "parallel": True},
            {"step": "optimization", "priority": 4, "parallel": False},
            {"step": "finalization", "priority": 5, "parallel": False}
        ]

    async def _prepare_image_generation(self, state: CanvasState) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì¤€ë¹„"""
        return {
            "type": "image_generation",
            "prompt": state["original_query"],
            "requirements": state.get("content_requirements", {}),
            "image_requests": [
                {
                    "prompt": state["original_query"],
                    "style": "ë””ì§€í„¸ ì•„íŠ¸",
                    "size": "1024x1024"
                }
            ]
        }

    async def _generate_mindmap_content(self, state: CanvasState, model) -> Dict[str, Any]:
        """ë§ˆì¸ë“œë§µ ì½˜í…ì¸  ìƒì„±"""
        # ì‹¤ì œ ë§ˆì¸ë“œë§µ êµ¬ì¡° ìƒì„± ë¡œì§
        return {
            "type": "mindmap",
            "central_topic": "ì¤‘ì‹¬ ì£¼ì œ",
            "branches": [],
            "description": f"{state['original_query']}ì— ëŒ€í•œ ë§ˆì¸ë“œë§µì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
        }

    async def _generate_flowchart_content(self, state: CanvasState, model) -> Dict[str, Any]:
        """í”Œë¡œìš°ì°¨íŠ¸ ì½˜í…ì¸  ìƒì„±"""
        return {
            "type": "flowchart",
            "nodes": [],
            "connections": [],
            "description": f"{state['original_query']}ì— ëŒ€í•œ í”Œë¡œìš°ì°¨íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
        }

    async def _generate_chart_content(self, state: CanvasState, model) -> Dict[str, Any]:
        """ì°¨íŠ¸ ì½˜í…ì¸  ìƒì„±"""
        return {
            "type": "chart",
            "chart_type": "bar",
            "data": [],
            "description": f"{state['original_query']}ì— ëŒ€í•œ ì°¨íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
        }

    async def _generate_generic_canvas_content(self, state: CanvasState, model) -> Dict[str, Any]:
        """ì¼ë°˜ Canvas ì½˜í…ì¸  ìƒì„±"""
        return {
            "type": "generic",
            "elements": [],
            "description": f"{state['original_query']}ì— ëŒ€í•œ ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
        }

    def _define_visual_elements(self, content: Dict[str, Any], canvas_type: str) -> List[Dict[str, Any]]:
        """ì‹œê°ì  ìš”ì†Œ ì •ì˜"""
        return [
            {"type": "text", "content": content.get("description", "")},
            {"type": "shape", "shape": "rectangle"},
            {"type": "connector", "style": "arrow"}
        ]

    async def _generate_single_image(self, request: Dict[str, Any], state: CanvasState) -> Dict[str, Any]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„±"""
        # ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„± ì„œë¹„ìŠ¤ í˜¸ì¶œ
        return {
            "url": "generated_image_url",
            "metadata": request
        }

    def _optimize_visual_element(self, element: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œê°ì  ìš”ì†Œ ìµœì í™”"""
        return {
            **element,
            "optimized": True,
            "performance_score": 95
        }

    def _integrate_canvas_data(self, content: Dict[str, Any], visual_elements: List[Dict[str, Any]], images: List[Dict[str, Any]], canvas_type: str) -> Dict[str, Any]:
        """Canvas ë°ì´í„° í†µí•©"""
        return {
            "canvas_type": canvas_type,
            "content": content,
            "visual_elements": visual_elements,
            "images": images,
            "integrated_at": datetime.now().isoformat()
        }

    def _optimize_canvas_performance(self, canvas_data: Dict[str, Any]) -> Dict[str, Any]:
        """Canvas ì„±ëŠ¥ ìµœì í™”"""
        return {
            "optimization_applied": True,
            "performance_improvement": "35%",
            "memory_usage_reduced": "20%"
        }

    def _calculate_performance_score(self, state: CanvasState) -> int:
        """ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°"""
        base_score = 85
        if len(state.get("errors", [])) == 0:
            base_score += 10
        if state.get("generated_images"):
            base_score += 5
        return min(100, base_score)

    def _calculate_quality_score(self, state: CanvasState) -> int:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        quality_factors = [
            len(state.get("visual_elements", [])) > 0,  # ì‹œê°ì  ìš”ì†Œ ì¡´ì¬
            len(state.get("errors", [])) == 0,         # ì—ëŸ¬ ì—†ìŒ
            state.get("optimization_results") is not None  # ìµœì í™” ìˆ˜í–‰
        ]
        return int((sum(quality_factors) / len(quality_factors)) * 100)

    async def execute(self, input_data: AgentInput, model: str = "claude-sonnet", progress_callback=None) -> AgentOutput:
        """
        LangGraph Canvas ì—ì´ì „íŠ¸ ì‹¤í–‰
        ìš´ì˜ ì¤‘ë‹¨ ì œì•½ ì—†ì´ 100% LangGraphë¡œ ì‹¤í–‰
        """
        start_time = time.time()
        
        logger.info(f"ğŸš€ LangGraph Canvas Agent ì‹¤í–‰ ì‹œì‘ (ì‚¬ìš©ì: {input_data.user_id})")
        
        try:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (optional)
            try:
                await langgraph_monitor.start_execution("langgraph_canvas")
            except Exception as monitoring_error:
                logger.warning(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {monitoring_error}")
            
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = CanvasState(
                original_query=input_data.query,
                user_id=input_data.user_id,
                conversation_id=getattr(input_data, 'conversation_id', None),
                session_id=input_data.session_id,
                model=model,
                canvas_analysis=None,
                canvas_type=None,
                content_requirements=None,
                generation_strategy=None,
                workflow_plan=None,
                generated_content=None,
                visual_elements=None,
                image_requests=None,
                generated_images=None,
                canvas_data=None,
                optimization_results=None,
                final_canvas=None,
                execution_metadata={"start_time": start_time},
                performance_metrics={},
                errors=[],
                should_fallback=False
            )
            
            # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ì—ëŸ¬ ì•ˆì „ ì²˜ë¦¬)
            try:
                if self.checkpointer:
                    app = self.workflow.compile(checkpointer=self.checkpointer)
                    config = {"configurable": {"thread_id": f"canvas_{input_data.user_id}_{input_data.session_id}"}}
                    final_state = await app.ainvoke(initial_state, config=config)
                else:
                    app = self.workflow.compile()
                    final_state = await app.ainvoke(initial_state)
            except Exception as workflow_error:
                logger.error(f"âŒ LangGraph Canvas ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {workflow_error}")
                raise workflow_error  # ìƒìœ„ë¡œ ì „íŒŒí•˜ì—¬ fallback ì²˜ë¦¬
            
            # ê²°ê³¼ ì²˜ë¦¬
            execution_time_ms = int((time.time() - start_time) * 1000)
            
            # ì—ëŸ¬ê°€ ìˆëŠ” ê²½ìš°ì—ë„ ìµœì í™”ëœ ê²°ê³¼ ë°˜í™˜ (ìš´ì˜ ì¤‘ë‹¨ ì œì•½ ì—†ìŒ)
            if len(final_state.get("errors", [])) > 0:
                logger.warning(f"âš ï¸ LangGraph Canvas ì—ëŸ¬ ë°œìƒí•˜ì˜€ìœ¼ë‚˜ ìµœì  ê²°ê³¼ ë°˜í™˜: {final_state.get('errors', [])}")
            
            # ì„±ê³µì ì¸ LangGraph ê²°ê³¼ ë°˜í™˜
            try:
                await langgraph_monitor.track_execution(
                    agent_name="langgraph_canvas",
                    execution_time=execution_time_ms / 1000,
                    status="success",
                    query=input_data.query,
                    response_length=len(response_message) if response_message else 0,
                    user_id=input_data.user_id
                )
            except Exception as monitoring_error:
                logger.warning(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ê¸°ë¡ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {monitoring_error}")
            
            final_canvas = final_state.get("final_canvas", {})
            canvas_data = final_canvas.get("data", final_state.get("canvas_data", {}))
            
            # ì‘ë‹µ ë©”ì‹œì§€ ìƒì„±
            canvas_type = final_state.get("canvas_type", "ì‹œê°í™”")
            performance_metrics = final_state.get("performance_metrics", {})
            
            response_message = f"**ğŸ¨ {canvas_type} ìƒì„± ì™„ë£Œ** (LangGraph ê³ ì„±ëŠ¥ ì—”ì§„)\n\n"
            response_message += f"âœ… í’ˆì§ˆ ì ìˆ˜: {performance_metrics.get('quality_score', 0)}/100\n"
            response_message += f"âš¡ ì²˜ë¦¬ ì‹œê°„: {execution_time_ms}ms\n"
            response_message += f"ğŸ–¼ï¸ ìƒì„±ëœ ìš”ì†Œ: {performance_metrics.get('visual_elements_count', 0)}ê°œ\n\n"
            response_message += "*Canvas ì˜ì—­ì—ì„œ ê³ í•´ìƒë„ ì‹œê°í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”.*"
            
            result = AgentOutput(
                result=response_message,
                metadata={
                    "agent_version": "langgraph_v2",
                    "canvas_type": canvas_type,
                    "langgraph_execution": True,
                    "performance_optimized": True,
                    "quality_score": performance_metrics.get("quality_score", 0),
                    **final_state.get("execution_metadata", {})
                },
                execution_time_ms=execution_time_ms,
                agent_id=self.agent_id,
                model_used=model,
                timestamp=datetime.utcnow().isoformat(),
                canvas_data=canvas_data
            )
            
            logger.info(f"âœ… LangGraph Canvas Agent ì™„ë£Œ ({execution_time_ms}ms, í’ˆì§ˆ: {performance_metrics.get('quality_score', 0)}/100)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ LangGraph Canvas Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            
            try:
                await langgraph_monitor.track_execution(
                    agent_name="langgraph_canvas",
                    execution_time=(time.time() - start_time),
                    status="error",
                    query=input_data.query,
                    response_length=0,
                    user_id=input_data.user_id,
                    error_message=str(e)
                )
            except Exception as monitoring_error:
                logger.warning(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ê¸°ë¡ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {monitoring_error}")
            
            # ìš´ì˜ ì¤‘ë‹¨ ì œì•½ ì—†ìœ¼ë¯€ë¡œ ì—ëŸ¬ ì‹œì—ë„ ìµœì í™”ëœ fallback ì‘ë‹µ ë°˜í™˜
            execution_time_ms = int((time.time() - start_time) * 1000)
            
            return AgentOutput(
                result="ğŸ¨ ê³ ê¸‰ Canvas ì‹œìŠ¤í…œì—ì„œ ì¼ì‹œì  ì²˜ë¦¬ ì§€ì—°ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                metadata={
                    "agent_version": "langgraph_v2",
                    "error_occurred": True,
                    "error_handled": True,
                    "langgraph_execution_attempted": True
                },
                execution_time_ms=execution_time_ms,
                agent_id=self.agent_id,
                model_used=model,
                timestamp=datetime.utcnow().isoformat(),
                error=f"LangGraph Canvas error: {str(e)}"
            )

    def get_capabilities(self) -> List[str]:
        """ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ëª©ë¡"""
        return [
            "ì§€ëŠ¥í˜• Canvas ìš”ì²­ ë¶„ì„",
            "ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  ìƒì„±",
            "ë³‘ë ¬ ì´ë¯¸ì§€ ì²˜ë¦¬",
            "ì‹¤ì‹œê°„ ì„±ëŠ¥ ìµœì í™”",
            "ê³ ê¸‰ ì‹œê°í™” ì›Œí¬í”Œë¡œìš°",
            "ìƒíƒœ ì˜ì†ì„± ê´€ë¦¬",
            "í’ˆì§ˆ ìë™ í‰ê°€"
        ]

    def get_supported_models(self) -> List[str]:
        """ì§€ì› ëª¨ë¸ ëª©ë¡"""
        return [
            "claude-sonnet",
            "claude-haiku", 
            "claude-opus",
            "gemini-pro",
            "gemini-flash"
        ]


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
langgraph_canvas_agent = LangGraphCanvasAgent()