"""
LangGraph ê¸°ë°˜ Supervisor Agent - ì™„ì „í•œ ì§€ëŠ¥í˜• ë¼ìš°íŒ… ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ ì‹œìŠ¤í…œ

ìµœì‹  LangGraph StateGraphë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  
ì ì ˆí•œ Worker ì—ì´ì „íŠ¸ë“¤ì—ê²Œ ìµœì í™”ëœ ë°©ì‹ìœ¼ë¡œ ë¶„ë°°í•˜ëŠ” ê³ ê¸‰ ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import time
import asyncio
import json
import uuid
from typing import Dict, Any, List, Optional, TypedDict, Union, Annotated, Callable
from datetime import datetime
from enum import Enum
from dataclasses import dataclass
import logging
import operator

# LangGraph í•µì‹¬ imports
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.types import Send
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# ê¸°ì¡´ ì‹œìŠ¤í…œ imports
from app.agents.base import BaseAgent, AgentInput, AgentOutput, ConversationContext
from app.agents.supervisor import supervisor_agent, IntentType
from app.agents.routing.intent_classifier import dynamic_intent_classifier
from app.agents.langgraph.web_search_langgraph import langgraph_web_search_agent
from app.agents.langgraph.canvas_langgraph import langgraph_canvas_agent
from app.agents.langgraph.information_gap_langgraph import langgraph_information_gap_analyzer
from app.agents.langgraph.parallel_processor import langgraph_parallel_processor
from app.core.config import settings
from app.core.feature_flags import is_langgraph_enabled, LangGraphFeatureFlags
from app.services.langgraph_monitor import langgraph_monitor

logger = logging.getLogger(__name__)


class SupervisorState(TypedDict):
    """LangGraph Supervisor ìƒíƒœ ì •ì˜"""
    # ì…ë ¥ ë°ì´í„°
    original_query: str
    user_id: str
    session_id: Optional[str]
    conversation_context: Optional[Dict[str, Any]]
    model: str
    
    # ë¶„ì„ ë‹¨ê³„
    intent_analysis: Optional[Dict[str, Any]]
    context_evaluation: Optional[Dict[str, Any]]
    complexity_assessment: Optional[Dict[str, Any]]
    
    # ë¼ìš°íŒ… ì „ëµ
    routing_strategy: Optional[Dict[str, Any]]
    selected_agents: Optional[List[Dict[str, Any]]]
    execution_plan: Optional[Dict[str, Any]]
    
    # ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì§‘ (Reducer ì‚¬ìš©)
    agent_results: Annotated[List[Dict[str, Any]], operator.add]
    parallel_results: Optional[List[Dict[str, Any]]]
    
    # ê²°ê³¼ í†µí•©
    integrated_response: Optional[str]
    final_output: Optional[str]
    
    # ì„±ëŠ¥ ë° í’ˆì§ˆ ë©”íŠ¸ë¦­
    execution_metadata: Dict[str, Any]
    quality_metrics: Dict[str, Any]
    routing_confidence: float
    
    # ì—ëŸ¬ ì²˜ë¦¬ ë° fallback
    errors: Annotated[List[str], operator.add]
    fallback_attempts: Annotated[List[Dict[str, Any]], operator.add]
    should_fallback: bool


class AgentType(Enum):
    """ì—ì´ì „íŠ¸ ìœ í˜•"""
    WEB_SEARCH = "web_search"
    CANVAS = "canvas"
    INFORMATION_GAP = "information_gap"
    PARALLEL_PROCESSOR = "parallel_processor"
    MULTIMODAL_RAG = "multimodal_rag"
    GENERAL_CHAT = "general_chat"


class ExecutionMode(Enum):
    """ì‹¤í–‰ ëª¨ë“œ"""
    SINGLE_AGENT = "single_agent"          # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
    SEQUENTIAL = "sequential"              # ìˆœì°¨ ì‹¤í–‰
    PARALLEL = "parallel"                  # ë³‘ë ¬ ì‹¤í–‰
    CONDITIONAL = "conditional"            # ì¡°ê±´ë¶€ ì‹¤í–‰
    INTERACTIVE = "interactive"            # ëŒ€í™”í˜• ì‹¤í–‰


@dataclass
class AgentSelection:
    """ì—ì´ì „íŠ¸ ì„ íƒ ì •ë³´"""
    agent_type: AgentType
    confidence: float
    priority: int
    expected_execution_time: float
    resource_requirements: Dict[str, Any]
    dependencies: List[str] = None


class LangGraphSupervisorAgent(BaseAgent):
    """LangGraph ê¸°ë°˜ Supervisor Agent"""
    
    def __init__(self):
        super().__init__(
            agent_id="langgraph_supervisor",
            name="LangGraph Supervisor ì—ì´ì „íŠ¸",
            description="LangGraph StateGraphë¡œ êµ¬í˜„ëœ ê³ ê¸‰ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ ì‹œìŠ¤í…œ"
        )
        
        # ë ˆê±°ì‹œ Supervisor (fallbackìš©)
        self.legacy_supervisor = supervisor_agent
        
        # Worker ì—ì´ì „íŠ¸ ë“±ë¡
        self.worker_agents = {
            AgentType.WEB_SEARCH: langgraph_web_search_agent,
            AgentType.CANVAS: langgraph_canvas_agent,
            AgentType.INFORMATION_GAP: langgraph_information_gap_analyzer,
            AgentType.PARALLEL_PROCESSOR: langgraph_parallel_processor,
            # AgentType.MULTIMODAL_RAG: langgraph_multimodal_rag,  # ì¶”í›„ êµ¬í˜„
        }
        
        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        self.workflow = self._build_workflow()
        
        # PostgreSQL ì²´í¬í¬ì¸í„° ì„¤ì •
        if settings.DATABASE_URL:
            self.checkpointer = PostgresSaver.from_conn_string(
                settings.DATABASE_URL,
                
            )
        else:
            self.checkpointer = None
            logger.warning("DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ - ì²´í¬í¬ì¸í„° ë¹„í™œì„±í™”")

    def _build_workflow(self) -> StateGraph:
        """LangGraph Supervisor ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        
        # StateGraph ìƒì„±
        workflow = StateGraph(SupervisorState)
        
        # ë…¸ë“œ ì •ì˜ - 8ë‹¨ê³„ ê³ ë„í™”ëœ ê´€ë¦¬ íŒŒì´í”„ë¼ì¸
        workflow.add_node("analyze_intent", self._analyze_intent_node)
        workflow.add_node("evaluate_context", self._evaluate_context_node)
        workflow.add_node("assess_complexity", self._assess_complexity_node)
        workflow.add_node("plan_routing_strategy", self._plan_routing_strategy_node)
        workflow.add_node("select_agents", self._select_agents_node)
        workflow.add_node("execute_agents", self._execute_agents_node)
        workflow.add_node("integrate_results", self._integrate_results_node)
        workflow.add_node("finalize_response", self._finalize_response_node)
        
        # ì—£ì§€ ì •ì˜ - ì„ í˜• íŒŒì´í”„ë¼ì¸
        workflow.set_entry_point("analyze_intent")
        workflow.add_edge("analyze_intent", "evaluate_context")
        workflow.add_edge("evaluate_context", "assess_complexity")
        workflow.add_edge("assess_complexity", "plan_routing_strategy")
        workflow.add_edge("plan_routing_strategy", "select_agents")
        workflow.add_edge("select_agents", "execute_agents")
        workflow.add_edge("execute_agents", "integrate_results")
        workflow.add_edge("integrate_results", "finalize_response")
        workflow.add_edge("finalize_response", END)
        
        # ì¡°ê±´ë¶€ ì—£ì§€ (ë³µì¡í•œ ë¼ìš°íŒ… ë¡œì§)
        workflow.add_conditional_edges(
            "analyze_intent",
            self._should_continue,
            {
                "continue": "evaluate_context",
                "fallback": END
            }
        )
        
        workflow.add_conditional_edges(
            "plan_routing_strategy",
            self._determine_execution_mode,
            {
                "single_agent": "select_agents",
                "parallel": "select_agents",
                "sequential": "select_agents",
                "interactive": "execute_agents"  # ë°”ë¡œ ì‹¤í–‰ìœ¼ë¡œ
            }
        )
        
        workflow.add_conditional_edges(
            "integrate_results",
            self._should_retry_failed_agents,
            {
                "retry": "execute_agents",
                "continue": "finalize_response"
            }
        )
        
        return workflow

    async def _analyze_intent_node(self, state: SupervisorState) -> Dict[str, Any]:
        """ì˜ë„ ë¶„ì„ ë…¸ë“œ - ê³ ê¸‰ ì˜ë„ ë¶„ë¥˜ ë° íŒŒì•…"""
        try:
            logger.info(f"ğŸ§  LangGraph Supervisor: ì˜ë„ ë¶„ì„ ì¤‘... (query: {state['original_query'][:50]})")
            
            model = self._get_llm_model(state["model"])
            
            # ê¸°ì¡´ dynamic_intent_classifier í™œìš©í•˜ë˜ ë” ìƒì„¸í•œ ë¶„ì„
            intent_prompt = ChatPromptTemplate.from_messages([
                ("system", """ê³ ê¸‰ ì˜ë„ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë‹¤ì¸µì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.

ë¶„ì„ í•­ëª©:
1. ì£¼ìš” ì˜ë„ (primary_intent): web_search, canvas, general_chat, multi_step, etc.
2. ë¶€ì°¨ì  ì˜ë„ë“¤ (secondary_intents): ë³µí•©ì  ìš”êµ¬ì‚¬í•­
3. ê°ì •ì  ë§¥ë½ (emotional_context): ê¸´ê¸‰ì„±, ì¤‘ìš”ë„, ê°ì • ìƒíƒœ
4. ê¸°ìˆ ì  ë³µì¡ë„ (technical_complexity): ë‹¨ìˆœ/ë³´í†µ/ë³µì¡/ê³ ê¸‰
5. ìƒí˜¸ì‘ìš© ìš”êµ¬ë„ (interaction_level): ì¼íšŒì„±/ëŒ€í™”í˜•/ì—°ì†í˜•
6. ê°œì¸í™” í•„ìš”ì„± (personalization_need): ì—†ìŒ/ë³´í†µ/ë†’ìŒ/ë§¤ìš°ë†’ìŒ
7. ì‹¤ì‹œê°„ì„± ìš”êµ¬ (real_time_requirement): ì—†ìŒ/ì„ í˜¸/í•„ìˆ˜

ê° í•­ëª©ì— ëŒ€í•´ ì‹ ë¢°ë„ì™€ ê·¼ê±°ë¥¼ í¬í•¨í•˜ì—¬ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""),
                ("human", """ì§ˆë¬¸: "{query}"
ëŒ€í™” ë§¥ë½: {context}

ì´ ì§ˆë¬¸ì„ ë‹¤ì¸µì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.""")
            ])
            
            context = state.get("conversation_context", {})
            response = await model.ainvoke(intent_prompt.format_messages(
                query=state["original_query"],
                context=json.dumps(context, ensure_ascii=False) if context else "ì—†ìŒ"
            ))
            
            try:
                intent_analysis = json.loads(response.content)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„
                intent_analysis = {
                    "primary_intent": "general_chat",
                    "secondary_intents": [],
                    "emotional_context": {"urgency": "normal", "importance": "medium"},
                    "technical_complexity": "ë³´í†µ",
                    "interaction_level": "ì¼íšŒì„±",
                    "personalization_need": "ë³´í†µ",
                    "real_time_requirement": "ì—†ìŒ",
                    "confidence": 0.7
                }
            
            return {
                "intent_analysis": intent_analysis,
                "routing_confidence": intent_analysis.get("confidence", 0.7),
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "intent_analysis_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "errors": [f"ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"],
                "should_fallback": True
            }

    async def _evaluate_context_node(self, state: SupervisorState) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ í‰ê°€ ë…¸ë“œ - ëŒ€í™” ë§¥ë½ ë° ì‚¬ìš©ì ìƒí™© ë¶„ì„"""
        try:
            logger.info("ğŸ§  LangGraph Supervisor: ì»¨í…ìŠ¤íŠ¸ í‰ê°€ ì¤‘...")
            
            model = self._get_llm_model(state["model"])
            context = state.get("conversation_context", {})
            intent_analysis = state.get("intent_analysis", {})
            
            context_prompt = ChatPromptTemplate.from_messages([
                ("system", """ëŒ€í™” ë§¥ë½ í‰ê°€ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒì„ ì¢…í•© ë¶„ì„í•˜ì„¸ìš”:

í‰ê°€ í•­ëª©:
1. ëŒ€í™” ì—°ì†ì„± (continuity): ì´ì „ ëŒ€í™”ì™€ì˜ ì—°ê´€ì„±
2. ì •ë³´ ì¶•ì ë„ (information_accumulation): ëŒ€í™” ì¤‘ ìˆ˜ì§‘ëœ ì •ë³´ëŸ‰
3. ì‚¬ìš©ì ìƒíƒœ (user_state): ë§Œì¡±ë„, í˜¼ë€ë„, ì§„í–‰ë„
4. ë§¥ë½ ì™„ê²°ì„± (context_completeness): í•„ìš”í•œ ë°°ê²½ ì •ë³´ ì¶©ì¡±ë„
5. ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ (workflow_stage): ì´ˆê¸°/ì¤‘ê°„/ì¢…ë£Œ ë‹¨ê³„
6. ê°œì¸í™” ìˆ˜ì¤€ (personalization_level): ê°œë³„ ë§ì¶¤ ì •ë„

JSON í˜•ì‹ìœ¼ë¡œ ì¢…í•© í‰ê°€ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”."""),
                ("human", """í˜„ì¬ ì§ˆë¬¸: "{query}"
ì˜ë„ ë¶„ì„ ê²°ê³¼: {intent_analysis}
ëŒ€í™” ì»¨í…ìŠ¤íŠ¸: {context}

ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¢…í•© í‰ê°€í•´ì£¼ì„¸ìš”.""")
            ])
            
            response = await model.ainvoke(context_prompt.format_messages(
                query=state["original_query"],
                intent_analysis=json.dumps(intent_analysis, ensure_ascii=False, indent=2),
                context=json.dumps(context, ensure_ascii=False, indent=2) if context else "ì—†ìŒ"
            ))
            
            try:
                context_evaluation = json.loads(response.content)
            except json.JSONDecodeError:
                context_evaluation = {
                    "continuity": 0.5,
                    "information_accumulation": 0.3,
                    "user_state": {"satisfaction": 0.7, "confusion": 0.2, "progress": 0.5},
                    "context_completeness": 0.6,
                    "workflow_stage": "ì¤‘ê°„",
                    "personalization_level": 0.4,
                    "confidence": 0.6
                }
            
            return {
                "context_evaluation": context_evaluation,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "context_evaluation_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ì»¨í…ìŠ¤íŠ¸ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                "errors": [f"ì»¨í…ìŠ¤íŠ¸ í‰ê°€ ì‹¤íŒ¨: {str(e)}"]
            }

    async def _assess_complexity_node(self, state: SupervisorState) -> Dict[str, Any]:
        """ë³µì¡ë„ í‰ê°€ ë…¸ë“œ - ì‘ì—… ë³µì¡ë„ ë° ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ë¶„ì„"""
        try:
            logger.info("ğŸ§  LangGraph Supervisor: ë³µì¡ë„ í‰ê°€ ì¤‘...")
            
            model = self._get_llm_model(state["model"])
            intent_analysis = state.get("intent_analysis", {})
            context_evaluation = state.get("context_evaluation", {})
            
            complexity_prompt = ChatPromptTemplate.from_messages([
                ("system", """ì‘ì—… ë³µì¡ë„ í‰ê°€ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒì„ ë¶„ì„í•˜ì„¸ìš”:

í‰ê°€ ê¸°ì¤€:
1. ì •ë³´ ì²˜ë¦¬ ë³µì¡ë„ (1-5): í•„ìš”í•œ ì •ë³´ì˜ ì–‘ê³¼ ë³µì¡ì„±
2. ê³„ì‚° ë³µì¡ë„ (1-5): ì²˜ë¦¬ì— í•„ìš”í•œ ì—°ì‚°ëŸ‰
3. ìƒí˜¸ì‘ìš© ë³µì¡ë„ (1-5): ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš© íšŸìˆ˜/ë³µì¡ì„±
4. í†µí•© ë³µì¡ë„ (1-5): ì—¬ëŸ¬ ì†ŒìŠ¤/ê²°ê³¼ í†µí•©ì˜ ì–´ë ¤ì›€
5. ì‹œê°„ ë¯¼ê°ë„ (1-5): ì‹¤ì‹œê°„ ì²˜ë¦¬ ìš”êµ¬ë„
6. ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ): ì „ì²´ ì²˜ë¦¬ ì˜ˆìƒ ì‹œê°„
7. ì¶”ì²œ ì‹¤í–‰ ëª¨ë“œ: single_agent/sequential/parallel/interactive

JSON í˜•ì‹ìœ¼ë¡œ ìƒì„¸í•œ ë³µì¡ë„ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”."""),
                ("human", """ì§ˆë¬¸: "{query}"
ì˜ë„ ë¶„ì„: {intent_analysis}
ì»¨í…ìŠ¤íŠ¸ í‰ê°€: {context_evaluation}

ì´ ì‘ì—…ì˜ ë³µì¡ë„ë¥¼ ì¢…í•© í‰ê°€í•´ì£¼ì„¸ìš”.""")
            ])
            
            response = await model.ainvoke(complexity_prompt.format_messages(
                query=state["original_query"],
                intent_analysis=json.dumps(intent_analysis, ensure_ascii=False),
                context_evaluation=json.dumps(context_evaluation, ensure_ascii=False)
            ))
            
            try:
                complexity_assessment = json.loads(response.content)
            except json.JSONDecodeError:
                complexity_assessment = {
                    "information_processing": 3,
                    "computational": 2,
                    "interaction": 2,
                    "integration": 2,
                    "time_sensitivity": 2,
                    "estimated_processing_time": 10.0,
                    "recommended_execution_mode": "single_agent",
                    "overall_complexity": "ë³´í†µ"
                }
            
            return {
                "complexity_assessment": complexity_assessment,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "complexity_assessment_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ë³µì¡ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                "errors": [f"ë³µì¡ë„ í‰ê°€ ì‹¤íŒ¨: {str(e)}"]
            }

    async def _plan_routing_strategy_node(self, state: SupervisorState) -> Dict[str, Any]:
        """ë¼ìš°íŒ… ì „ëµ ìˆ˜ë¦½ ë…¸ë“œ"""
        try:
            logger.info("ğŸ§  LangGraph Supervisor: ë¼ìš°íŒ… ì „ëµ ìˆ˜ë¦½ ì¤‘...")
            
            model = self._get_llm_model(state["model"])
            intent_analysis = state.get("intent_analysis", {})
            complexity_assessment = state.get("complexity_assessment", {})
            
            strategy_prompt = ChatPromptTemplate.from_messages([
                ("system", """ë¼ìš°íŒ… ì „ëµ ìˆ˜ë¦½ ì „ë¬¸ê°€ë¡œì„œ ìµœì ì˜ ì‹¤í–‰ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë“¤:
- web_search: ì›¹ ê²€ìƒ‰ ë° ì •ë³´ ìˆ˜ì§‘
- canvas: ì‹œê°ì  ì½˜í…ì¸  ìƒì„± (ì´ë¯¸ì§€, ë§ˆì¸ë“œë§µ ë“±)
- information_gap: ì •ë³´ ë¶€ì¡± ë¶„ì„ ë° ì¶”ê°€ ì •ë³´ ìš”ì²­
- parallel_processor: ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•œ ê³ ì„±ëŠ¥ ì‘ì—…
- general_chat: ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬

ì‹¤í–‰ ëª¨ë“œ:
- single_agent: í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬
- sequential: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
- parallel: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ë™ì‹œ ì‹¤í–‰
- interactive: ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í•„ìš”

JSON í˜•ì‹ìœ¼ë¡œ ìƒì„¸í•œ ë¼ìš°íŒ… ì „ëµì„ ì œê³µí•˜ì„¸ìš”."""),
                ("human", """ì§ˆë¬¸: "{query}"
ì˜ë„ ë¶„ì„: {intent_analysis}
ë³µì¡ë„ í‰ê°€: {complexity_assessment}

ìµœì ì˜ ë¼ìš°íŒ… ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.""")
            ])
            
            response = await model.ainvoke(strategy_prompt.format_messages(
                query=state["original_query"],
                intent_analysis=json.dumps(intent_analysis, ensure_ascii=False),
                complexity_assessment=json.dumps(complexity_assessment, ensure_ascii=False)
            ))
            
            try:
                routing_strategy = json.loads(response.content)
            except json.JSONDecodeError:
                # ê¸°ë³¸ ë¼ìš°íŒ… ì „ëµ
                primary_intent = intent_analysis.get("primary_intent", "general_chat")
                routing_strategy = {
                    "execution_mode": "single_agent",
                    "primary_agent": self._map_intent_to_agent(primary_intent),
                    "backup_agents": [],
                    "parallel_eligible": False,
                    "interaction_required": False,
                    "estimated_total_time": 10.0,
                    "confidence": 0.7
                }
            
            return {
                "routing_strategy": routing_strategy,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "routing_strategy_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ë¼ìš°íŒ… ì „ëµ ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            return {
                "errors": [f"ë¼ìš°íŒ… ì „ëµ ìˆ˜ë¦½ ì‹¤íŒ¨: {str(e)}"]
            }

    async def _select_agents_node(self, state: SupervisorState) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì„ íƒ ë…¸ë“œ"""
        try:
            logger.info("ğŸ§  LangGraph Supervisor: ì—ì´ì „íŠ¸ ì„ íƒ ì¤‘...")
            
            routing_strategy = state.get("routing_strategy", {})
            complexity_assessment = state.get("complexity_assessment", {})
            
            # ì„ íƒëœ ì—ì´ì „íŠ¸ë“¤
            selected_agents = []
            
            execution_mode = routing_strategy.get("execution_mode", "single_agent")
            primary_agent = routing_strategy.get("primary_agent", "general_chat")
            
            if execution_mode == "single_agent":
                selected_agents.append({
                    "agent_type": primary_agent,
                    "priority": 1,
                    "expected_time": complexity_assessment.get("estimated_processing_time", 10.0),
                    "confidence": routing_strategy.get("confidence", 0.7)
                })
            elif execution_mode in ["sequential", "parallel"]:
                # ì£¼ìš” ì—ì´ì „íŠ¸
                selected_agents.append({
                    "agent_type": primary_agent,
                    "priority": 1,
                    "expected_time": complexity_assessment.get("estimated_processing_time", 10.0) * 0.6,
                    "confidence": routing_strategy.get("confidence", 0.7)
                })
                
                # ë°±ì—… ì—ì´ì „íŠ¸ë“¤
                backup_agents = routing_strategy.get("backup_agents", [])
                for i, backup_agent in enumerate(backup_agents[:2]):  # ìµœëŒ€ 2ê°œ
                    selected_agents.append({
                        "agent_type": backup_agent,
                        "priority": i + 2,
                        "expected_time": complexity_assessment.get("estimated_processing_time", 10.0) * 0.4,
                        "confidence": 0.6
                    })
            
            # ì‹¤í–‰ ê³„íš ìƒì„±
            execution_plan = {
                "mode": execution_mode,
                "agents": selected_agents,
                "total_estimated_time": sum(a.get("expected_time", 0) for a in selected_agents),
                "parallel_eligible": routing_strategy.get("parallel_eligible", False),
                "fallback_strategy": "legacy_supervisor"
            }
            
            return {
                "selected_agents": selected_agents,
                "execution_plan": execution_plan,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "agent_selection_completed_at": time.time(),
                    "selected_agents_count": len(selected_agents)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ì—ì´ì „íŠ¸ ì„ íƒ ì‹¤íŒ¨: {e}")
            return {
                "errors": [f"ì—ì´ì „íŠ¸ ì„ íƒ ì‹¤íŒ¨: {str(e)}"]
            }

    async def _execute_agents_node(self, state: SupervisorState) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ ë…¸ë“œ"""
        try:
            logger.info("ğŸš€ LangGraph Supervisor: ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
            
            execution_plan = state.get("execution_plan", {})
            selected_agents = state.get("selected_agents", [])
            
            if not selected_agents:
                return {"errors": ["ì„ íƒëœ ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤"]}
            
            agent_results = []
            execution_mode = execution_plan.get("mode", "single_agent")
            
            # ì‹¤í–‰ ëª¨ë“œë³„ ì²˜ë¦¬
            if execution_mode == "single_agent":
                # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
                primary_agent = selected_agents[0]
                result = await self._execute_single_agent(primary_agent, state)
                agent_results.append(result)
                
            elif execution_mode == "sequential":
                # ìˆœì°¨ ì‹¤í–‰
                for agent_config in selected_agents:
                    result = await self._execute_single_agent(agent_config, state)
                    agent_results.append(result)
                    
                    # ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ì—ì´ì „íŠ¸ë¡œ fallback ê°€ëŠ¥
                    if result.get("success", False):
                        break
                        
            elif execution_mode == "parallel":
                # ë³‘ë ¬ ì‹¤í–‰
                tasks = []
                for agent_config in selected_agents:
                    task = self._execute_single_agent(agent_config, state)
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for i, result in enumerate(results):
                    if isinstance(result, Exception):
                        agent_results.append({
                            "agent_type": selected_agents[i].get("agent_type", "unknown"),
                            "success": False,
                            "error": str(result),
                            "execution_time": 0
                        })
                    else:
                        agent_results.append(result)
            
            return {
                "agent_results": agent_results,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "agents_execution_completed_at": time.time(),
                    "executed_agents_count": len(agent_results)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "errors": [f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"]
            }

    async def _integrate_results_node(self, state: SupervisorState) -> Dict[str, Any]:
        """ê²°ê³¼ í†µí•© ë…¸ë“œ"""
        try:
            logger.info("ğŸ”„ LangGraph Supervisor: ê²°ê³¼ í†µí•© ì¤‘...")
            
            agent_results = state.get("agent_results", [])
            intent_analysis = state.get("intent_analysis", {})
            
            if not agent_results:
                return {"integrated_response": "ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}
            
            # ì„±ê³µí•œ ê²°ê³¼ë“¤ë§Œ í•„í„°ë§
            successful_results = [r for r in agent_results if r.get("success", False)]
            
            if not successful_results:
                return {
                    "integrated_response": "ëª¨ë“  ì—ì´ì „íŠ¸ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    "errors": [f"ì‹¤í–‰ ì‹¤íŒ¨: {r.get('error', 'Unknown error')}" for r in agent_results]
                }
            
            model = self._get_llm_model(state["model"])
            
            integration_prompt = ChatPromptTemplate.from_messages([
                ("system", """ê²°ê³¼ í†µí•© ì „ë¬¸ê°€ë¡œì„œ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì ì˜ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

í†µí•© ì›ì¹™:
1. ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ìš°ì„  í™œìš©
2. ì¤‘ë³µëœ ì •ë³´ëŠ” ì œê±°í•˜ê³  ë³´ì™„ ì •ë³´ëŠ” ì¶”ê°€
3. ì‚¬ìš©ìì˜ ì›ë˜ ì˜ë„ì— ë§ê²Œ êµ¬ì„±
4. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ì™€ ì¶”ë¡ ëœ ì •ë³´ êµ¬ë¶„
5. ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì •ë¦¬

í•œêµ­ì–´ë¡œ ì™„ì „í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”."""),
                ("human", """ì›ë³¸ ì§ˆë¬¸: "{query}"
ì‚¬ìš©ì ì˜ë„: {intent}

ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ë“¤:
{results}

ì´ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬ ìµœì ì˜ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.""")
            ])
            
            # ê²°ê³¼ ìš”ì•½ ìƒì„±
            results_summary = []
            for result in successful_results:
                agent_type = result.get("agent_type", "unknown")
                response = result.get("response", "")
                metadata = result.get("metadata", {})
                
                results_summary.append({
                    "agent": agent_type,
                    "response": response[:500],  # 500ì ì œí•œ
                    "confidence": metadata.get("confidence", 0.7),
                    "execution_time": result.get("execution_time", 0)
                })
            
            response = await model.ainvoke(integration_prompt.format_messages(
                query=state["original_query"],
                intent=json.dumps(intent_analysis, ensure_ascii=False),
                results=json.dumps(results_summary, ensure_ascii=False, indent=2)
            ))
            
            integrated_response = response.content
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            quality_metrics = {
                "successful_agents": len(successful_results),
                "total_agents": len(agent_results),
                "success_rate": len(successful_results) / len(agent_results) * 100,
                "avg_confidence": sum(r.get("metadata", {}).get("confidence", 0.7) for r in successful_results) / len(successful_results),
                "total_execution_time": sum(r.get("execution_time", 0) for r in agent_results)
            }
            
            return {
                "integrated_response": integrated_response,
                "quality_metrics": quality_metrics,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "integration_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {e}")
            return {
                "errors": [f"ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {str(e)}"],
                "integrated_response": "ê²°ê³¼ í†µí•© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }

    async def _finalize_response_node(self, state: SupervisorState) -> Dict[str, Any]:
        """ìµœì¢… ì‘ë‹µ ìƒì„± ë…¸ë“œ"""
        try:
            logger.info("ğŸ¯ LangGraph Supervisor: ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...")
            
            integrated_response = state.get("integrated_response", "")
            quality_metrics = state.get("quality_metrics", {})
            routing_confidence = state.get("routing_confidence", 0.7)
            
            # ìµœì¢… ì‘ë‹µì— í’ˆì§ˆ ë° ì„±ëŠ¥ ì •ë³´ ì¶”ê°€ (ê°œë°œ ëª¨ë“œì—ì„œë§Œ)
            final_output = integrated_response
            
            if settings.DEBUG and quality_metrics:
                success_rate = quality_metrics.get("success_rate", 0)
                avg_confidence = quality_metrics.get("avg_confidence", 0.7)
                
                if success_rate < 100:
                    final_output += f"\n\n*ì²˜ë¦¬ ì„±ê³µë¥ : {success_rate:.1f}%*"
                
                if routing_confidence > 0.9:
                    final_output += "\n\n*LangGraph ê³ ì„±ëŠ¥ ë¼ìš°íŒ…ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.*"
            
            return {
                "final_output": final_output,
                "execution_metadata": {
                    **state.get("execution_metadata", {}),
                    "finalization_completed_at": time.time()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ìµœì¢… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "final_output": "ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "errors": [f"ìµœì¢… ì‘ë‹µ ì‹¤íŒ¨: {str(e)}"]
            }

    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤

    def _should_continue(self, state: SupervisorState) -> str:
        """ì¡°ê±´ë¶€ ë¼ìš°íŒ…: ê³„ì† ì§„í–‰ ì—¬ë¶€ ê²°ì •"""
        if state.get("should_fallback", False) or len(state.get("errors", [])) > 3:
            return "fallback"
        return "continue"

    def _determine_execution_mode(self, state: SupervisorState) -> str:
        """ì¡°ê±´ë¶€ ë¼ìš°íŒ…: ì‹¤í–‰ ëª¨ë“œ ê²°ì •"""
        routing_strategy = state.get("routing_strategy", {})
        execution_mode = routing_strategy.get("execution_mode", "single_agent")
        
        # ìœ íš¨í•œ ì‹¤í–‰ ëª¨ë“œì¸ì§€ í™•ì¸
        valid_modes = ["single_agent", "parallel", "sequential", "interactive"]
        if execution_mode in valid_modes:
            return execution_mode
        return "single_agent"

    def _should_retry_failed_agents(self, state: SupervisorState) -> str:
        """ì¡°ê±´ë¶€ ë¼ìš°íŒ…: ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ ì¬ì‹œë„ ì—¬ë¶€"""
        quality_metrics = state.get("quality_metrics", {})
        success_rate = quality_metrics.get("success_rate", 100)
        retry_count = state.get("execution_metadata", {}).get("retry_count", 0)
        
        if success_rate < 50 and retry_count < 1:  # ì„±ê³µë¥  50% ë¯¸ë§Œì´ê³  ì¬ì‹œë„ 1íšŒ ë¯¸ë§Œ
            return "retry"
        return "continue"

    def _get_llm_model(self, model_name: str):
        """LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if "claude" in model_name.lower():
            return ChatAnthropic(
                model_name=model_name,
                anthropic_api_key=settings.ANTHROPIC_API_KEY,
                temperature=0.2
            )
        elif "gemini" in model_name.lower():
            return ChatGoogleGenerativeAI(
                model=model_name,
                google_api_key=settings.GOOGLE_API_KEY,
                temperature=0.2
            )
        else:
            return ChatAnthropic(
                model_name="claude-3-sonnet-20240229",
                anthropic_api_key=settings.ANTHROPIC_API_KEY,
                temperature=0.2
            )

    def _map_intent_to_agent(self, intent: str) -> str:
        """ì˜ë„ë¥¼ ì—ì´ì „íŠ¸ íƒ€ì…ìœ¼ë¡œ ë§¤í•‘"""
        intent_mapping = {
            "web_search": "web_search",
            "deep_research": "web_search",
            "canvas": "canvas",
            "general_chat": "general_chat",
            "multi_step": "parallel_processor",
            "clarification": "information_gap"
        }
        return intent_mapping.get(intent, "general_chat")

    async def _execute_single_agent(self, agent_config: Dict[str, Any], state: SupervisorState) -> Dict[str, Any]:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            agent_type_str = agent_config.get("agent_type", "general_chat")
            
            # ì—ì´ì „íŠ¸ íƒ€ì… ë³€í™˜
            try:
                agent_type = AgentType(agent_type_str)
            except ValueError:
                agent_type = AgentType.GENERAL_CHAT
            
            # í•´ë‹¹ ì—ì´ì „íŠ¸ ê°€ì ¸ì˜¤ê¸°
            worker_agent = self.worker_agents.get(agent_type)
            
            if not worker_agent:
                return {
                    "agent_type": agent_type_str,
                    "success": False,
                    "error": f"ì—ì´ì „íŠ¸ {agent_type_str}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    "execution_time": time.time() - start_time
                }
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ì„ ìœ„í•œ ì…ë ¥ ì¤€ë¹„
            agent_input = AgentInput(
                query=state["original_query"],
                user_id=state["user_id"],
                session_id=state["session_id"],
                context=state.get("conversation_context", {})
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await worker_agent.execute(agent_input, state["model"])
            
            execution_time = time.time() - start_time
            
            return {
                "agent_type": agent_type_str,
                "success": True,
                "response": result.result,
                "metadata": result.metadata,
                "execution_time": execution_time
            }
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨ ({agent_config.get('agent_type', 'unknown')}): {e}")
            
            return {
                "agent_type": agent_config.get("agent_type", "unknown"),
                "success": False,
                "error": str(e),
                "execution_time": execution_time
            }

    async def execute(self, input_data: AgentInput, model: str = "claude-sonnet", progress_callback=None) -> AgentOutput:
        """
        LangGraph Supervisor Agent ì‹¤í–‰
        Feature Flagì— ë”°ë¼ LangGraph ë˜ëŠ” Legacy ëª¨ë“œë¡œ ì‹¤í–‰
        """
        start_time = time.time()
        
        # Feature Flag í™•ì¸
        if not is_langgraph_enabled(
            LangGraphFeatureFlags.LANGGRAPH_SUPERVISOR, 
            input_data.user_id
        ):
            logger.info("ğŸ”„ Feature Flag: Legacy SupervisorAgent ì‚¬ìš©")
            return await self.legacy_supervisor.execute(input_data, model, progress_callback)
        
        logger.info(f"ğŸš€ LangGraph Supervisor Agent ì‹¤í–‰ ì‹œì‘ (ì‚¬ìš©ì: {input_data.user_id})")
        
        try:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (optional)
            try:
                await langgraph_monitor.start_execution("langgraph_supervisor")
            except Exception as monitoring_error:
                logger.warning(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {monitoring_error}")
            
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            conversation_context = {}
            if input_data.conversation_context:
                conversation_context = {
                    "current_focus_topic": input_data.conversation_context.current_focus_topic,
                    "interaction_count": input_data.conversation_context.interaction_count,
                    "user_preferences": input_data.conversation_context.user_preferences or {},
                    "previous_messages": input_data.conversation_context.previous_messages or []
                }
            elif input_data.context:
                conversation_context = input_data.context.get('conversation_context', {})
            
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = SupervisorState(
                original_query=input_data.query,
                user_id=input_data.user_id,
                session_id=input_data.session_id,
                conversation_context=conversation_context,
                model=model,
                intent_analysis=None,
                context_evaluation=None,
                complexity_assessment=None,
                routing_strategy=None,
                selected_agents=None,
                execution_plan=None,
                agent_results=[],
                parallel_results=None,
                integrated_response=None,
                final_output=None,
                execution_metadata={"start_time": start_time},
                quality_metrics={},
                routing_confidence=0.0,
                errors=[],
                fallback_attempts=[],
                should_fallback=False
            )
            
            # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ì—ëŸ¬ ì•ˆì „ ì²˜ë¦¬)
            try:
                if self.checkpointer:
                    app = self.workflow.compile(checkpointer=self.checkpointer)
                    config = {"configurable": {"thread_id": f"supervisor_{input_data.user_id}_{input_data.session_id}"}}
                    final_state = await app.ainvoke(initial_state, config=config)
                else:
                    app = self.workflow.compile()
                    final_state = await app.ainvoke(initial_state)
            except Exception as workflow_error:
                logger.error(f"âŒ LangGraph Supervisor ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {workflow_error}")
                raise workflow_error  # ìƒìœ„ë¡œ ì „íŒŒí•˜ì—¬ fallback ì²˜ë¦¬
            
            # ê²°ê³¼ ì²˜ë¦¬
            execution_time_ms = int((time.time() - start_time) * 1000)
            
            # ì—ëŸ¬ê°€ ìˆê±°ë‚˜ fallbackì´ í•„ìš”í•œ ê²½ìš°
            if final_state.get("should_fallback", False) or len(final_state.get("errors", [])) > 0:
                logger.warning("ğŸ”„ LangGraph Supervisor ì‹¤í–‰ ì‹¤íŒ¨ - Legacy ëª¨ë“œë¡œ fallback")
                langgraph_monitor.record_fallback("langgraph_supervisor", f"Errors: {final_state.get('errors', [])}")
                return await self.legacy_supervisor.execute(input_data, model, progress_callback)
            
            # ì„±ê³µì ì¸ LangGraph ê²°ê³¼ ë°˜í™˜
            final_output = final_state.get("final_output", "ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            quality_metrics = final_state.get("quality_metrics", {})
            routing_confidence = final_state.get("routing_confidence", 0.7)
            
            try:
                await langgraph_monitor.track_execution(
                    agent_name="langgraph_supervisor",
                    execution_time=execution_time_ms / 1000,
                    status="success",
                    query=input_data.query,
                    response_length=len(final_output) if final_output else 0,
                    user_id=input_data.user_id
                )
            except Exception as monitoring_error:
                logger.warning(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ê¸°ë¡ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {monitoring_error}")
            
            result = AgentOutput(
                result=final_output,
                metadata={
                    "agent_version": "langgraph_supervisor_v2",
                    "routing_system": "advanced_langgraph",
                    "routing_confidence": routing_confidence,
                    "supervisor_decision": final_state.get("routing_strategy", {}).get("execution_mode", "single_agent"),
                    "quality_metrics": quality_metrics,
                    "langgraph_execution": True,
                    "performance_optimized": True,
                    **final_state.get("execution_metadata", {})
                },
                execution_time_ms=execution_time_ms,
                agent_id=self.agent_id,
                model_used=model,
                timestamp=datetime.utcnow().isoformat()
            )
            
            logger.info(f"âœ… LangGraph Supervisor Agent ì™„ë£Œ ({execution_time_ms}ms, ì‹ ë¢°ë„: {routing_confidence:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"âŒ LangGraph Supervisor Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            
            # ì—ëŸ¬ ì‹œ ìë™ fallback
            try:
                await langgraph_monitor.track_execution(
                    agent_name="langgraph_supervisor",
                    execution_time=(time.time() - start_time),
                    status="error",
                    query=input_data.query,
                    response_length=0,
                    user_id=input_data.user_id,
                    error_message=str(e)
                )
            except Exception as monitoring_error:
                logger.warning(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ê¸°ë¡ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {monitoring_error}")
            
            langgraph_monitor.record_fallback("langgraph_supervisor", f"Exception: {str(e)}")
            
            logger.info("ğŸ”„ ì˜ˆì™¸ ë°œìƒ - Legacy SupervisorAgentë¡œ fallback")
            return await self.legacy_supervisor.execute(input_data, model, progress_callback)

    def get_capabilities(self) -> List[str]:
        """ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ëª©ë¡"""
        return [
            "ê³ ê¸‰ ì˜ë„ ë¶„ì„ ë° ë¶„ë¥˜",
            "ë‹¤ì¸µì  ì»¨í…ìŠ¤íŠ¸ í‰ê°€",
            "ì‘ì—… ë³µì¡ë„ ë° ë¦¬ì†ŒìŠ¤ ë¶„ì„",
            "ì§€ëŠ¥í˜• ë¼ìš°íŒ… ì „ëµ ìˆ˜ë¦½",
            "ë™ì  ì—ì´ì „íŠ¸ ì„ íƒ ë° ê´€ë¦¬",
            "ë‹¤ì¤‘ ì‹¤í–‰ ëª¨ë“œ ì§€ì›",
            "ì‹¤ì‹œê°„ ê²°ê³¼ í†µí•© ë° ìµœì í™”",
            "ìë™ í’ˆì§ˆ ê´€ë¦¬ ë° fallback"
        ]

    def get_supported_models(self) -> List[str]:
        """ì§€ì› ëª¨ë¸ ëª©ë¡"""
        return [
            "claude-sonnet",
            "claude-haiku", 
            "claude-opus",
            "gemini-pro",
            "gemini-flash"
        ]


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
langgraph_supervisor_agent = LangGraphSupervisorAgent()