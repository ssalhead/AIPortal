"""
Supervisor ì—ì´ì „íŠ¸ - ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ Worker ì—ì´ì „íŠ¸ì—ê²Œ ë¶„ë°°
"""

import time
from typing import Dict, Any, Optional
from enum import Enum
import logging

from app.agents.base import BaseAgent, AgentInput, AgentOutput
from app.agents.llm_router import llm_router
from app.agents.workers.web_search import web_search_agent
from app.agents.workers.information_gap_analyzer import information_gap_analyzer
from app.agents.workers.canvas import canvas_agent

logger = logging.getLogger(__name__)


class TaskType(Enum):
    """ì‘ì—… ìœ í˜•"""
    WEB_SEARCH = "web_search"
    DEEP_RESEARCH = "deep_research"
    MULTIMODAL_RAG = "multimodal_rag"
    CANVAS = "canvas"
    GENERAL_CHAT = "general_chat"


class SupervisorAgent(BaseAgent):
    """Supervisor ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            agent_id="supervisor",
            name="Supervisor ì—ì´ì „íŠ¸",
            description="ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ Worker ì—ì´ì „íŠ¸ì—ê²Œ ë¶„ë°°í•©ë‹ˆë‹¤"
        )
        
        # Worker ì—ì´ì „íŠ¸ ë“±ë¡ (information_gap_analyzerëŠ” ë‚´ë¶€ ë¡œì§ìœ¼ë¡œ ì‚¬ìš©)
        self.workers = {
            TaskType.WEB_SEARCH: web_search_agent,
            TaskType.CANVAS: canvas_agent,
            # TaskType.DEEP_RESEARCH: deep_search_agent,  # ì¶”í›„ êµ¬í˜„
            # TaskType.MULTIMODAL_RAG: multimodal_rag_agent,  # ì¶”í›„ êµ¬í˜„
        }
        
        # ì •ë³´ ë¶„ì„ê¸°ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©
        self.information_analyzer = information_gap_analyzer
    
    async def execute(self, input_data: AgentInput, model: str = "gemini", progress_callback=None) -> AgentOutput:
        """Supervisor ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        start_time = time.time()
        
        if not self.validate_input(input_data):
            raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ ë°ì´í„°")
        
        try:
            # 1ë‹¨ê³„: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì²´í¬
            conversation_context = input_data.context.get('conversation_context', {}) if input_data.context else {}
            previous_messages = conversation_context.get('previous_messages', [])
            
            # ê°•ë ¥í•œ ê²€ìƒ‰ ì§€ì‹œì–´ ì²´í¬ (ì •ë³´ ë¶„ì„ë³´ë‹¤ ìš°ì„ )
            strong_search_indicators = ["ê²€ìƒ‰í•´ì„œ", "ì°¾ì•„ì„œ", "ì¡°íšŒí•´ì„œ", "ì•Œì•„ë³´ê³ ", "ì›¹ì—ì„œ"]
            has_strong_search = any(indicator in input_data.query for indicator in strong_search_indicators)
            
            # ì´ì „ ëŒ€í™”ì—ì„œ ì •ë³´ ìš”ì²­ì´ ìˆì—ˆëŠ”ì§€ ì²´í¬
            recent_info_request = False
            if previous_messages and len(previous_messages) >= 2:
                last_ai_message = previous_messages[-1].get('content', '') if previous_messages[-1].get('role') == 'assistant' else ''
                if any(keyword in last_ai_message for keyword in ["ì•Œë ¤ì£¼ì„¸ìš”", "ì •ë³´", "ì§€ì—­", "ì–¸ì œ"]):
                    recent_info_request = True
            
            if has_strong_search or recent_info_request:
                # ê°•ë ¥í•œ ê²€ìƒ‰ ì§€ì‹œì–´ê°€ ìˆê±°ë‚˜ ìµœê·¼ ì •ë³´ ìš”ì²­ í›„ë¼ë©´ ë°”ë¡œ ì‘ì—… ë¶„ë¥˜ë¡œ
                self.logger.info("ê°•ë ¥í•œ ê²€ìƒ‰ ì§€ì‹œì–´ ê°ì§€ ë˜ëŠ” ì •ë³´ ìš”ì²­ í›„ì† - ì •ë³´ ë¶„ì„ ìƒëµ")
                task_type = await self._analyze_task_type_direct(input_data.query, model)
            else:
                # 2ë‹¨ê³„: ì¼ë°˜ì ì¸ ê²½ìš° ì •ë³´ ë¶„ì„ ì‹¤í–‰
                self.logger.info("ìë™ ì •ë³´ ë¶„ì„ ì‹œì‘")
                
                # ì •ë³´ ë¶€ì¡± ë¶„ì„ ì‹¤í–‰
                info_analysis_result = await self.information_analyzer.execute(input_data, model)
                
                # ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš° ì •ë³´ ìš”ì²­ ì‘ë‹µ ë°˜í™˜
                if info_analysis_result.metadata.get("needs_more_info", False):
                    self.logger.info("ì •ë³´ ë¶€ì¡± ê°ì§€ - ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì •ë³´ ìš”ì²­")
                    # Supervisor ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    info_analysis_result.metadata["supervisor_decision"] = "information_request"
                    info_analysis_result.metadata["auto_analysis"] = True
                    return info_analysis_result
                
                # 3ë‹¨ê³„: ì •ë³´ê°€ ì¶©ë¶„í•œ ê²½ìš° ì‘ì—… ìœ í˜• ë¶„ì„
                self.logger.info("ì •ë³´ ì¶©ì¡± - ì‘ì—… ìœ í˜• ë¶„ì„ ì§„í–‰")
                task_type = await self._analyze_task_type_direct(input_data.query, model)
            
            # 4ë‹¨ê³„: ì ì ˆí•œ Worker ì—ì´ì „íŠ¸ ì„ íƒ
            worker_agent = self._select_worker(task_type)
            
            if worker_agent:
                # Worker ì—ì´ì „íŠ¸ ì‹¤í–‰ (progress_callback ì „ë‹¬)
                self.logger.info(f"ğŸ¯ ì‘ì—…ì„ {task_type.value} ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„ - ì—ì´ì „íŠ¸ ID: {worker_agent.agent_id}")
                if task_type == TaskType.CANVAS:
                    self.logger.info(f"ğŸ¨ Canvas ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘ - ì¿¼ë¦¬: {input_data.query[:100]}...")
                result = await worker_agent.execute(input_data, model, progress_callback)
                
                # Supervisor ë©”íƒ€ë°ì´í„° ì¶”ê°€
                result.metadata["supervisor_decision"] = task_type.value
                result.metadata["delegated_to"] = worker_agent.agent_id
                result.metadata["auto_analysis_passed"] = True
                
                return result
            else:
                # ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Workerê°€ ì—†ëŠ” ê²½ìš° ì§ì ‘ ì²˜ë¦¬
                return await self._handle_directly(input_data, model, start_time)
                
        except Exception as e:
            self.logger.error(f"Supervisor ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            execution_time = int((time.time() - start_time) * 1000)
            
            return self.create_output(
                result=f"ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                metadata={"error": str(e)},
                execution_time_ms=execution_time,
                model_used=model
            )
    
    async def _analyze_task_type_direct(self, query: str, model: str) -> TaskType:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì‘ì—… ìœ í˜• ê²°ì • (LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ë¶„ë¥˜)"""
        try:
            prompt = f"""
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì‘ì—… ìœ í˜•ì„ ê²°ì •í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{query}"

**ì‘ì—… ìœ í˜• ë¶„ë¥˜ ê¸°ì¤€**:

1. **web_search** - ì¸í„°ë„· ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°:
   - ì‹¤ì‹œê°„/ìµœì‹  ì •ë³´ (ë‚ ì”¨, ë‰´ìŠ¤, ì£¼ê°€, í˜„ì¬ ìƒí™©)
   - ì‡¼í•‘/êµ¬ë§¤ ì •ë³´ (ì œí’ˆ ê°€ê²©, ì¬ê³ , ì„œì  ë„ì„œ, ì˜¨ë¼ì¸ëª°)
   - ì§€ì—­ ì •ë³´ (ë§›ì§‘, ë³‘ì›, êµí†µ, ê·¼ì²˜ ìƒì )
   - ë¹„êµ/ì¶”ì²œ (ì œí’ˆ ë¹„êµ, ì„œë¹„ìŠ¤ ì¶”ì²œ, ë² ìŠ¤íŠ¸ì…€ëŸ¬)
   - ì‚¬ì‹¤ í™•ì¸ (ìµœì‹  ì •ë³´, í†µê³„, í˜„í™©)

2. **deep_research** - ì‹¬ì¸µ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°:
   - ë³µí•©ì  ë¶„ì„ ("ë¹„êµ ë¶„ì„", "ì‹¬ì¸µ ì—°êµ¬", "ì¢…í•©ì  ê²€í† ")
   - í•™ìˆ ì  ì¡°ì‚¬ (ë…¼ë¬¸, ë³´ê³ ì„œ, ì „ë¬¸ ìë£Œ)
   - ë‹¤ê°ë„ ê²€í†  (ì¥ë‹¨ì  ë¶„ì„, íŠ¸ë Œë“œ ë¶„ì„)

3. **canvas** - ì‹œê°ì  ì°½ì‘:
   - ì´ë¯¸ì§€ ìƒì„± ("ê·¸ë ¤ì¤˜", "ë§Œë“¤ì–´ì¤˜", "ë””ìì¸", "ì´ë¯¸ì§€ ìƒì„±", "ì‚¬ì§„", "ê·¸ë¦¼", "ì¼ëŸ¬ìŠ¤íŠ¸", "AI ì´ë¯¸ì§€")
   - ë‹¤ì´ì–´ê·¸ë¨ ("ë§ˆì¸ë“œë§µ", "ì°¨íŠ¸", "ê·¸ë˜í”„", "ì‹œê°í™”", "ë„í‘œ")
   - ì‹œê°ì  ì½˜í…ì¸  ("í¬ìŠ¤í„°", "ë¡œê³ ", "ë°°ê²½", "ìºë¦­í„°", "í’ê²½")

4. **general_chat** - ì¼ë°˜ ëŒ€í™”:
   - ê¸°ë³¸ ì§€ì‹ ì§ˆë¬¸ (ê°œë… ì„¤ëª…, ì •ì˜, ë°©ë²•)
   - ì°½ì‘ ìš”ì²­ (ì‹œ, ì†Œì„¤, ì•„ì´ë””ì–´)
   - ì¼ìƒ ëŒ€í™” (ìƒë‹´, ì˜ê²¬)

**ë¶„ë¥˜ ì˜ˆì‹œ**:
- "ì„œì ì—ì„œ íŒë§¤ì¤‘ì¸ ì±… ì¶”ì²œí•´ì¤˜" â†’ web_search (ì‡¼í•‘/ì¶”ì²œ ì •ë³´)
- "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?" â†’ web_search (ì‹¤ì‹œê°„ ì •ë³´)
- "íŒŒì´ì¬ ë¬¸ë²• ì„¤ëª…í•´ì¤˜" â†’ general_chat (ê¸°ë³¸ ì§€ì‹)
- "ë§ˆì¼€íŒ… ì „ëµ ë¶„ì„í•´ì¤˜" â†’ deep_research (ë³µí•© ë¶„ì„)
- "ë¡œê³  ê·¸ë ¤ì¤˜" â†’ canvas (ì‹œê°ì  ì°½ì‘)

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì •í™•íˆ ë°˜í™˜í•´ì£¼ì„¸ìš”: web_search, deep_research, canvas, general_chat
"""
            
            response, _ = await llm_router.generate_response(model, prompt, include_datetime=False)
            task_type_str = response.strip().lower()
            
            # TaskTypeìœ¼ë¡œ ë³€í™˜
            if task_type_str == "web_search":
                return TaskType.WEB_SEARCH
            elif task_type_str == "deep_research":
                return TaskType.DEEP_RESEARCH
            elif task_type_str == "canvas":
                return TaskType.CANVAS
            else:
                return TaskType.GENERAL_CHAT
                
        except Exception as e:
            self.logger.warning(f"ì‘ì—… ìœ í˜• ë¶„ì„ ì‹¤íŒ¨, ìŠ¤ë§ˆíŠ¸ fallback ì‚¬ìš©: {e}")
            return self._smart_fallback_analysis(query)
    
    async def _smart_information_analysis(self, query: str, model: str) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ì •ë³´ ë¶€ì¡± ë¶„ì„ - ë§¥ë½ì  ì´í•´ë¡œ ì •ë³´ ìš”ì²­ í•„ìš”ì„± íŒë‹¨"""
        try:
            prompt = f"""
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{query}"

**ë¶„ì„ ê¸°ì¤€**:
- ì§ˆë¬¸ì´ êµ¬ì²´ì ì´ê³  ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥í•œê°€?
- ì§€ì—­, ì‹œê°„, ì·¨í–¥ ë“± ê°œì¸í™” ì •ë³´ê°€ í•„ìš”í•œê°€?
- ë§¥ë½ì´ë‚˜ ìƒì„¸ ì¡°ê±´ì´ ë¶€ì¡±í•œê°€?

**ì •ë³´ ìš”ì²­ì´ í•„ìš”í•œ ê²½ìš°**:
- ìœ„ì¹˜ ì •ë³´ ë¶€ì¡±: "ê·¼ì²˜ ë§›ì§‘" (ì–´ë”” ê·¼ì²˜ì¸ì§€ ë¶ˆëª…í™•)
- ì‹œê°„ ì •ë³´ ë¶€ì¡±: "ì–¸ì œê°€ ì¢‹ì„ê¹Œ?" (ë¬´ì—‡ì— ëŒ€í•œ ì‹œê¸°ì¸ì§€ ë¶ˆëª…í™•)
- ì·¨í–¥/ì¡°ê±´ ë¶€ì¡±: "ì¶”ì²œí•´ì¤˜" (ì—°ë ¹, ì¥ë¥´, ì˜ˆì‚° ë“± ì¡°ê±´ ë¶ˆëª…í™•)
- ê³¼ë„í•˜ê²Œ ëª¨í˜¸í•œ ì§ˆë¬¸

**ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ê²½ìš°**:
- êµ¬ì²´ì ì¸ ì •ë³´ ìš”ì²­: "ì„œìš¸ ë‚ ì”¨", "íŒŒì´ì¬ ë¬¸ë²•"
- ì¼ë°˜ì ì¸ ì¶”ì²œ: "ì–´ë¦°ì´ ë„ì„œ ì¶”ì²œ" (ì¼ë°˜ì  ë²”ì£¼)
- ëª…í™•í•œ ì§ˆë¬¸: "ë¹„íŠ¸ì½”ì¸ í˜„ì¬ ê°€ê²©"

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
íŒë‹¨: [needs_more_info ë˜ëŠ” can_answer_directly]
ì´ìœ : [í•œ ë¬¸ì¥ ì„¤ëª…]
ì‹ ë¢°ë„: [0.1-1.0]
"""

            response, _ = await llm_router.generate_response(model, prompt, include_datetime=False)
            lines = response.strip().split('\n')
            
            needs_analysis = False
            reason = "ì¶©ë¶„í•œ ì •ë³´ê°€ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤"
            confidence = 0.7
            
            for line in lines:
                if line.startswith('íŒë‹¨:'):
                    judgment = line.split(':', 1)[1].strip().lower()
                    needs_analysis = 'needs_more_info' in judgment
                elif line.startswith('ì´ìœ :'):
                    reason = line.split(':', 1)[1].strip()
                elif line.startswith('ì‹ ë¢°ë„:'):
                    try:
                        confidence = float(line.split(':', 1)[1].strip())
                        confidence = max(0.1, min(1.0, confidence))
                    except:
                        pass
            
            return {
                "needs_analysis": needs_analysis,
                "reason": reason,
                "confidence": confidence,
                "method": "llm_based"
            }
            
        except Exception as e:
            self.logger.error(f"LLM ì •ë³´ ë¶„ì„ ì‹¤íŒ¨, ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©: {e}")
            # LLM ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ fallback
            simple_incomplete_patterns = ["ì¶”ì²œ", "ì–´ë–¤", "ë­ê°€", "ì–¸ì œ", "ì–´ë””"]
            has_incomplete = any(pattern in query for pattern in simple_incomplete_patterns)
            is_too_short = len(query.split()) < 4
            
            return {
                "needs_analysis": has_incomplete and is_too_short,
                "reason": "ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ ê²°ê³¼",
                "confidence": 0.5,
                "method": "fallback_heuristic"
            }
    
    
    def _smart_fallback_analysis(self, query: str) -> TaskType:
        """ë‹¨ìˆœí™”ëœ fallback ë¶„ì„ - LLM ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©"""
        # Canvas ê´€ë ¨ í‚¤ì›Œë“œ (ëª…í™•í•œ ì‹œê°ì  ìš”ì²­)
        canvas_keywords = [
            "ê·¸ë ¤", "ë§Œë“¤ì–´", "ìƒì„±", "ì‹œê°í™”", "ì°¨íŠ¸", "ê·¸ë˜í”„", "ë‹¤ì´ì–´ê·¸ë¨", "ë§ˆì¸ë“œë§µ", "ê·¸ë¦¼", "ì´ë¯¸ì§€",
            "ë””ìì¸", "í¬ìŠ¤í„°", "ë¡œê³ ", "ë°°ê²½", "ìºë¦­í„°", "í’ê²½", "ì¼ëŸ¬ìŠ¤íŠ¸", "ì‚¬ì§„", "AI ì´ë¯¸ì§€"
        ]
        matched_keywords = [k for k in canvas_keywords if k in query]
        if matched_keywords:
            self.logger.info(f"ğŸ¨ Canvas í‚¤ì›Œë“œ ê°ì§€ (fallback) - ë§¤ì¹­ í‚¤ì›Œë“œ: {matched_keywords}, ì¿¼ë¦¬: {query[:50]}...")
            return TaskType.CANVAS
        
        # ëª…í™•í•œ ê²€ìƒ‰ ìš”ì²­ í‚¤ì›Œë“œ
        search_keywords = ["ê²€ìƒ‰", "ì°¾ì•„", "ì¶”ì²œ", "ë‚ ì”¨", "ê°€ê²©", "í˜„ì¬", "ìµœì‹ ", "ì˜¤ëŠ˜"]
        if any(k in query for k in search_keywords):
            return TaskType.WEB_SEARCH
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ì²˜ë¦¬
        return TaskType.GENERAL_CHAT
    
    def _select_worker(self, task_type: TaskType) -> Optional[BaseAgent]:
        """ì‘ì—… ìœ í˜•ì— ë”°ë¥¸ Worker ì—ì´ì „íŠ¸ ì„ íƒ"""
        worker = self.workers.get(task_type)
        if worker:
            return worker
        
        # í•´ë‹¹ Workerê°€ ì—†ëŠ” ê²½ìš° ëŒ€ì²´ Worker ì„ íƒ
        if task_type == TaskType.DEEP_RESEARCH:
            # Deep Researchê°€ ì—†ìœ¼ë©´ Web Searchë¡œ ëŒ€ì²´
            return self.workers.get(TaskType.WEB_SEARCH)
        elif task_type == TaskType.MULTIMODAL_RAG:
            # Multimodal RAGê°€ ì—†ìœ¼ë©´ Web Searchë¡œ ëŒ€ì²´
            return self.workers.get(TaskType.WEB_SEARCH)
        
        return None
    
    async def _handle_directly(self, input_data: AgentInput, model: str, start_time: float) -> AgentOutput:
        """Supervisorê°€ ì§ì ‘ ì²˜ë¦¬"""
        try:
            prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: "{input_data.query}"

ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
í˜„ì¬ íŠ¹ë³„í•œ ë„êµ¬ë‚˜ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì§€ë§Œ, 
ê°€ëŠ¥í•œ í•œ ìœ ìš©í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            response, _ = await llm_router.generate_response(model, prompt)
            execution_time = int((time.time() - start_time) * 1000)
            
            return self.create_output(
                result=response,
                metadata={
                    "handled_by": "supervisor_direct",
                    "reason": "no_suitable_worker_available"
                },
                execution_time_ms=execution_time,
                model_used=model
            )
            
        except Exception as e:
            self.logger.error(f"ì§ì ‘ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            execution_time = int((time.time() - start_time) * 1000)
            
            return self.create_output(
                result="ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                metadata={"error": str(e)},
                execution_time_ms=execution_time,
                model_used=model
            )
    
    def get_capabilities(self) -> list[str]:
        """Supervisor ê¸°ëŠ¥ ëª©ë¡"""
        return [
            "ìš”ì²­ ë¶„ì„",
            "ì‘ì—… ë¶„ë°°",
            "Worker ê´€ë¦¬",
            "ì‘ë‹µ ì¡°ì •"
        ]
    
    def get_supported_models(self) -> list[str]:
        """ì§€ì›í•˜ëŠ” ëª¨ë¸ ëª©ë¡"""
        return ["gemini", "claude", "openai"]
    
    def get_available_workers(self) -> Dict[str, str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ Worker ì—ì´ì „íŠ¸ ëª©ë¡"""
        return {
            task_type.value: worker.name 
            for task_type, worker in self.workers.items()
        }
    
    async def analyze_and_suggest_agent(self, query: str, current_agent: str, model: str = "gemini") -> Dict[str, Any]:
        """í˜„ì¬ ì—ì´ì „íŠ¸ì™€ ë‹¤ë¥¸ ë” ì í•©í•œ ì—ì´ì „íŠ¸ë¥¼ ì œì•ˆ"""
        try:
            # ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„ (ì •ë³´ ë¶„ì„ ì—†ì´ ë°”ë¡œ ì‘ì—… ìœ í˜• ë¶„ì„)
            suggested_task_type = await self._analyze_task_type_direct(query, model)
            suggested_agent = suggested_task_type.value
            
            # í˜„ì¬ ì—ì´ì „íŠ¸ì™€ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ ì œì•ˆ
            if suggested_agent != current_agent and suggested_agent != "general_chat":
                # ìƒì„¸ ë¶„ì„ìœ¼ë¡œ ì‹ ë¢°ë„ ë° ì´ìœ  ìƒì„±
                confidence, reason = await self._analyze_suggestion_details(
                    query, current_agent, suggested_agent, model
                )
                
                return {
                    "needs_switch": True,
                    "suggested_agent": suggested_agent,
                    "confidence": confidence,
                    "reason": reason,
                    "current_agent": current_agent
                }
            
            return {"needs_switch": False}
            
        except Exception as e:
            self.logger.error(f"ì—ì´ì „íŠ¸ ì œì•ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"needs_switch": False, "error": str(e)}
    
    async def _analyze_suggestion_details(self, query: str, current_agent: str, suggested_agent: str, model: str) -> tuple[float, str]:
        """ì œì•ˆ ìƒì„¸ ë¶„ì„ - ì‹ ë¢°ë„ì™€ ì´ìœ  ìƒì„±"""
        try:
            agent_descriptions = {
                "none": "ì¼ë°˜ ì±„íŒ…",
                "web_search": "ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìµœì‹  ì •ë³´ ì¡°íšŒ",
                "deep_research": "ì‹¬ì¸µì ì¸ ë¶„ì„ê³¼ ì—°êµ¬",
                "canvas": "ì´ë¯¸ì§€ ìƒì„±, ë§ˆì¸ë“œë§µ, ì‹œê°ì  ì°½ì‘",
                "multimodal_rag": "ë¬¸ì„œ ë° ì´ë¯¸ì§€ ë¶„ì„"
            }
            
            prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì—ì´ì „íŠ¸ ì „í™˜ì´ í•„ìš”í•œ ì´ìœ ì™€ ì‹ ë¢°ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
í˜„ì¬ ì—ì´ì „íŠ¸: {agent_descriptions.get(current_agent, current_agent)}
ì œì•ˆ ì—ì´ì „íŠ¸: {agent_descriptions.get(suggested_agent, suggested_agent)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
ì‹ ë¢°ë„: [0.1-1.0 ì‚¬ì´ì˜ ìˆ«ì]
ì´ìœ : [í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ]

ì˜ˆì‹œ:
ì‹ ë¢°ë„: 0.9
ì´ìœ : ìµœì‹  ì£¼ê°€ ì •ë³´ ì¡°íšŒëŠ” ì›¹ ê²€ìƒ‰ì´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
"""
            
            response, _ = await llm_router.generate_response(model, prompt)
            lines = response.strip().split('\n')
            
            confidence = 0.7  # ê¸°ë³¸ê°’
            reason = f"{agent_descriptions.get(suggested_agent, suggested_agent)}ê°€ ì´ ì‘ì—…ì— ë” ì í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            
            for line in lines:
                if line.startswith('ì‹ ë¢°ë„:'):
                    try:
                        confidence = float(line.split(':')[1].strip())
                        confidence = max(0.1, min(1.0, confidence))  # ë²”ìœ„ ì œí•œ
                    except:
                        pass
                elif line.startswith('ì´ìœ :'):
                    reason = line.split(':', 1)[1].strip()
            
            return confidence, reason
            
        except Exception as e:
            self.logger.warning(f"ì œì•ˆ ìƒì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7, f"{suggested_agent.replace('_', ' ')}ì´ ë” ì í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"


# Supervisor ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
supervisor_agent = SupervisorAgent()